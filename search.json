[
  {
    "objectID": "variant_calling.html",
    "href": "variant_calling.html",
    "title": "Variant calling",
    "section": "",
    "text": "Short variant calling\nNow that we have quality-controlled the BAM files, we can go ahead with the variant calling itself. For this, we used mutect2 which is a somatic variant caller from GATK based on HaplotypeCaller. In addition to the expected bam files and references genome, the mutect2 command requires some additional input:\n\n--intervals: the intervals of our target regions. This is in the interval_list format.\n-normal: the sample name of the normal sample. So, the SM tag of the read group of the normal sample.\n--germline-resource: know sites of germline variants with their allele frequencies in the population. These are used to estimate the confidence of a germline variant in the normal sample.\n--panel-of-normals: A VCF generated from normal samples that contain sites with known technical artifacts. Ideally, you create a PON from your own normal samples, but this is typically recommended if you have more than 40 normal samples. Therefore, here, we use a pre-generated PON from the 1000 genomes project. More information on PON in this article.\n\n\n\n\n\n\n\nExercise\n\n\n\nCreate a script called 03_run_mutect2.sh. After that, check out the manual of Mutect2 and replace the placeholders FIXME with the required values of the Mutect2 below command and run it:\n\n#!/usr/bin/env bash\n\nALIGNDIR=~/project/course_data/alignments\nREFDIR=~/project/course_data/reference\nRESOURCEDIR=~/project/course_data/resources\nVARIANTDIR=~/project/course_data/variants\n\nmkdir -p $VARIANTDIR\n\ngatk Mutect2 \\\n-R FIXME \\\n--intervals \"$REFDIR\"/exome_regions.bed.interval_list \\\n-I FIXME \\\n-I FIXME \\\n-normal FIXME \\\n--germline-resource \"$RESOURCEDIR\"/af-only-gnomad.hg38.subset.vcf.gz \\\n--panel-of-normals \"$RESOURCEDIR\"/1000g_pon.hg38.subset.vcf.gz \\\n-O \"$VARIANTDIR\"/somatic.vcf.gz\n\n\n\n\n\n\n\n\n\nCaution\n\n\n\nThis takes a while to run. Have a break!\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n#!/usr/bin/env bash\n\nALIGNDIR=~/project/course_data/alignments\nREFDIR=~/project/course_data/reference\nRESOURCEDIR=~/project/course_data/resources\nVARIANTDIR=~/project/course_data/variants\n\nmkdir -p $VARIANTDIR\n\ngatk Mutect2 \\\n-R \"$REFDIR\"/ref_genome.fa \\\n--intervals \"$REFDIR\"/exome_regions.bed.interval_list \\\n-I \"$ALIGNDIR\"/tumor.recal.bam \\\n-I \"$ALIGNDIR\"/normal.recal.bam \\\n-normal normal \\\n--germline-resource \"$RESOURCEDIR\"/af-only-gnomad.hg38.subset.vcf.gz \\\n--panel-of-normals \"$RESOURCEDIR\"/1000g_pon.hg38.subset.vcf.gz \\\n-O \"$VARIANTDIR\"/somatic.vcf.gz\n\n\n\nAfter calling the variants we can do an initial filtering step. We do this with FilterMutectCalls. This method takes technical artifacts, possibility of germline variants, and sequencing error in account, calculates an error probability and tries to optimize between recall and precision.\n\n\n\n\n\n\nExercise\n\n\n\nCreate a script called 04_filter_mutect_calls.sh in ~/project/scripts. From the script, run the command to filter the somatic variants:\n#!/usr/bin/env bash\n\nREFDIR=~/project/course_data/reference\nVARIANTDIR=~/project/course_data/variants\n\ngatk FilterMutectCalls \\\n-R \"$REFDIR\"/ref_genome.fa \\\n-V \"$VARIANTDIR\"/somatic.vcf.gz \\\n-O \"$VARIANTDIR\"/somatic.filtered.vcf.gz\nHow many variants were kept? What were the main reason for filtering them out?\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe filtering information is in the 7th column of the vcf, so you can do something like:\nbcftools view -H somatic.vcf.gz | cut -f 7 | sort | uniq -c | sort -nr | head -n 10\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nTo get the number of variants in the unfiltered vcf:\nbcftools view -H somatic.vcf.gz | wc -l\nResulting in 467 unfiltered variants.\nTo get the 10 most frequently occurring filters in the filter column of the filtered vcf:\nbcftools view -H somatic.filtered.vcf.gz | cut -f 7 | sort | uniq -c | sort -nr | head -n 10\nResulting in:\n133 PASS\n48 weak_evidence\n26 normal_artifact;strand_bias\n21 panel_of_normals\n17 normal_artifact\n13 normal_artifact;slippage;weak_evidence\n13 clustered_events;normal_artifact;strand_bias\n12 germline;multiallelic;normal_artifact;panel_of_normals\n12 base_qual;normal_artifact;strand_bias\n9 strand_bias;weak_evidence\nSo most variants were filtered out, and most of the variants were filtered out because of ‘weak evidence’.\nIn order to figure out what that means we can check out the vcf header:\nbcftools view -h somatic.filtered.vcf.gz | grep \"^##FILTER\"\nResulting in:\n##FILTER=&lt;ID=FAIL,Description=\"Fail the site if all alleles fail but for different reasons.\"&gt;\n##FILTER=&lt;ID=PASS,Description=\"Site contains at least one allele that passes filters\"&gt;\n##FILTER=&lt;ID=base_qual,Description=\"alt median base quality\"&gt;\n##FILTER=&lt;ID=clustered_events,Description=\"Clustered events observed in the tumor\"&gt;\n##FILTER=&lt;ID=contamination,Description=\"contamination\"&gt;\n##FILTER=&lt;ID=duplicate,Description=\"evidence for alt allele is overrepresented by apparent duplicates\"&gt;\n##FILTER=&lt;ID=fragment,Description=\"abs(ref - alt) median fragment length\"&gt;\n##FILTER=&lt;ID=germline,Description=\"Evidence indicates this site is germline, not somatic\"&gt;\n##FILTER=&lt;ID=haplotype,Description=\"Variant near filtered variant on same haplotype.\"&gt;\n##FILTER=&lt;ID=low_allele_frac,Description=\"Allele fraction is below specified threshold\"&gt;\n##FILTER=&lt;ID=map_qual,Description=\"ref - alt median mapping quality\"&gt;\n##FILTER=&lt;ID=multiallelic,Description=\"Site filtered because too many alt alleles pass tumor LOD\"&gt;\n##FILTER=&lt;ID=n_ratio,Description=\"Ratio of N to alt exceeds specified ratio\"&gt;\n##FILTER=&lt;ID=normal_artifact,Description=\"artifact_in_normal\"&gt;\n##FILTER=&lt;ID=orientation,Description=\"orientation bias detected by the orientation bias mixture model\"&gt;\n##FILTER=&lt;ID=panel_of_normals,Description=\"Blacklisted site in panel of normals\"&gt;\n##FILTER=&lt;ID=position,Description=\"median distance of alt variants from end of reads\"&gt;\n##FILTER=&lt;ID=possible_numt,Description=\"Allele depth is below expected coverage of NuMT in autosome\"&gt;\n##FILTER=&lt;ID=slippage,Description=\"Site filtered due to contraction of short tandem repeat region\"&gt;\n##FILTER=&lt;ID=strand_bias,Description=\"Evidence for alt allele comes from one read direction only\"&gt;\n##FILTER=&lt;ID=strict_strand,Description=\"Evidence for alt allele is not represented in both directions\"&gt;\n##FILTER=&lt;ID=weak_evidence,Description=\"Mutation does not meet likelihood threshold\"&gt;\nShowing us that these mutations do not meet the likelihood threshold, basically telling us that these are the variants filtered out because of the combined error probability based on technical artifacts, possibility of germline variants, and sequencing error. The other filters are so called ‘hard filters’, meaning that by themselves they do not meet a fixed threshold.\n\n\n\nLet’s check out the VCF in a bit more detail. We’d like to have an idea what kind of variants are in there, and what for example their variant allele frequency is.\nFirst, we can check what the variants look like:\nbcftools view -H somatic.filtered.vcf.gz | head\nShowing us that both the FORMAT and INFO fields are filled with information. To check out the meaning of what is in the INFO field you can run:\nbcftools view -h somatic.filtered.vcf.gz | grep \"^##INFO\"\nAnd you can do the same for the format fields:\nbcftools view -h somatic.filtered.vcf.gz | grep \"^##FORMAT\"\nTo summarize the vcf for information in the format or info fields you can use bcftools query. For example, for getting the likelihood of variant and depth of each sample, you can do the following (for the first 20 variants):\nbcftools query -f '%CHROM\\t%POS\\t%FILTER\\t\\t%INFO/TLOD\\t[%SAMPLE=%DP;]\\n' somatic.filtered.vcf.gz | head -20\n\n\n\n\n\n\nExercise\n\n\n\nInstead of the depth DP for each sample get the variant allele frequency for each sample, and compare that with the FILTER column.\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWe can check which tag contains the variant allele frequency in the vcf:\nbcftools view -h somatic.filtered.vcf.gz | grep \"^##FORMAT\"\nReturning:\n##FORMAT=&lt;ID=AD,Number=R,Type=Integer,Description=\"Allelic depths for the ref and alt alleles in the order listed\"&gt;\n##FORMAT=&lt;ID=AF,Number=A,Type=Float,Description=\"Allele fractions of alternate alleles in the tumor\"&gt;\n##FORMAT=&lt;ID=DP,Number=1,Type=Integer,Description=\"Approximate read depth (reads with MQ=255 or with bad mates are filtered)\"&gt;\n##FORMAT=&lt;ID=F1R2,Number=R,Type=Integer,Description=\"Count of reads in F1R2 pair orientation supporting each allele\"&gt;\n##FORMAT=&lt;ID=F2R1,Number=R,Type=Integer,Description=\"Count of reads in F2R1 pair orientation supporting each allele\"&gt;\n##FORMAT=&lt;ID=FAD,Number=R,Type=Integer,Description=\"Count of fragments supporting each allele.\"&gt;\n##FORMAT=&lt;ID=GQ,Number=1,Type=Integer,Description=\"Genotype Quality\"&gt;\n##FORMAT=&lt;ID=GT,Number=1,Type=String,Description=\"Genotype\"&gt;\n##FORMAT=&lt;ID=PGT,Number=1,Type=String,Description=\"Physical phasing haplotype information, describing how the alternate alleles are phased in relation to one another; will always be heterozygous and is not intended to describe called alleles\"&gt;\n##FORMAT=&lt;ID=PID,Number=1,Type=String,Description=\"Physical phasing ID information, where each unique ID within a given sample (but not across samples) connects records within a phasing group\"&gt;\n##FORMAT=&lt;ID=PL,Number=G,Type=Integer,Description=\"Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification\"&gt;\n##FORMAT=&lt;ID=PS,Number=1,Type=Integer,Description=\"Phasing set (typically the position of the first variant in the set)\"&gt;\n##FORMAT=&lt;ID=SB,Number=4,Type=Integer,Description=\"Per-sample component statistics which comprise the Fisher's Exact Test to detect strand bias.\"&gt;\nWhere AF contains ‘Allele fractions of alternate alleles in the tumor’, so that is the tag we are looking for. So, we replace DP with AF:\nbcftools query -f '%CHROM\\t%POS\\t%FILTER\\t\\t%INFO/TLOD\\t[%SAMPLE=%AF;]\\n' somatic.filtered.vcf.gz | head -30\nReturning:\nchr6    106265  map_qual;strand_bias;weak_evidence              3.99    normal=0.00671;tumor=0.01;\nchr6    325357  PASS            719.91  normal=0.001054;tumor=0.161;\nchr6    325783  PASS            1292.31 normal=0.0009626;tumor=0.224;\nchr6    325901  PASS            1030.6  normal=0.005447;tumor=0.183;\nchr6    325916  PASS            937.7   normal=0.004142;tumor=0.116;\nchr6    1742560 panel_of_normals                235.6   normal=0.02;tumor=0.41;\nchr6    1916336 PASS            187.23  normal=0.022;tumor=0.482;\nchr6    1930220 PASS            152.54  normal=0.016;tumor=0.207;\nchr6    2674999 PASS            190.32  normal=0.028;tumor=0.514;\nchr6    2834013 PASS            245.04  normal=0.02;tumor=0.494;\nchr6    2840548 PASS            274.4   normal=0.021;tumor=0.522;\nchr6    3110986 weak_evidence           3.03    normal=0.017;tumor=0.019;\nchr6    3723708 PASS            266.67  normal=0.017;tumor=0.42;\nchr6    4892169 weak_evidence           4.43    normal=0.024;tumor=0.02;\nchr6    5103987 germline;multiallelic;normal_artifact;panel_of_normals          13.57,257.27    normal=0.037,0.825;tumor=0.077,0.834;\nchr6    6250887 PASS            260.99  normal=0.018;tumor=0.459;\nchr6    7176847 PASS            107.39  normal=0.026;tumor=0.319;\nchr6    7585458 PASS            171.88  normal=0.015;tumor=0.283;\nchr6    7833697 PASS            122.24  normal=0.057;tumor=0.513;\nchr6    7883281 germline                99.5    normal=0.05;tumor=0.476;\nchr6    8054329 PASS            420.89  normal=0.045;tumor=0.446;\nchr6    9900366 panel_of_normals                525.07  normal=0.024;tumor=0.992;\nchr6    10397660        germline;multiallelic;slippage          3.21,50.94      normal=0.042,0.043;tumor=0.098,0.798;\nchr6    10398435        PASS            365.76  normal=0.013;tumor=0.943;\nchr6    10801908        PASS            91.41   normal=0.02;tumor=0.312;\nchr6    10989772        PASS            71.25   normal=0.041;tumor=0.49;\nchr6    11306007        PASS            209.24  normal=0.009359;tumor=0.4;\nchr6    13479062        germline;multiallelic;normal_artifact;panel_of_normals          4.63,5.86,13.96 normal=0.022,0.027,0.258;tumor=0.043,0.068,0.165;\nchr6    13977507        weak_evidence           3.4     normal=0.012;tumor=0.027;\nchr6    16147945        PASS            331.72  normal=0.014;tumor=0.978;\nWhere we see that if there’s the filter weak_evidence the VAF of the tumor is typically low.\n\n\n\n\n\nCopy number variation calling\nVariation of copy number in genes can have a large effect on the phenotype of a tumor. Therefore, we will also estimate the copy number variation occurring on chromosome 6 and 17. For that, we use CNVkit.\n\n\n\n\n\n\nExercise\n\n\n\nCheck out the documentation of CNVkit.py bash, and the helper (cnvkit.py batch -h), and replace the missing values at FIXME.\nAfter that, checkout the visualizations (tumor-scatter.png and tumor-scatter.png) at ~/project/course_data/variants/cnvkit. Do you see any evidence for copy number variation?\n#!/usr/bin/env bash\n\nALIGNDIR=~/project/course_data/alignments\nREFDIR=~/project/course_data/reference\nRESOURCEDIR=~/project/course_data/resources\nVARIANTDIR=~/project/course_data/variants\n\ncnvkit.py batch FIXME \\\n--normal FIXME \\\n--targets FIXME \\\n--fasta FIXME \\\n--annotate \"$RESOURCEDIR\"/refFlat.txt \\\n--output-reference \"$VARIANTDIR\"/reference.cnn \\\n--output-dir \"$VARIANTDIR\"/cnvkit/ \\\n--processes 4 \\\n--scatter \\\n--diagram\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe scale on the scatter plot is log2(copy ratio). So, if there is a duplication at one chromsome you would expect a copy ratio of 1.5 (3 chromsomes/2 chromsomes). The log2 of 1.5 is 0.58. So estimates at 0.58 mean a gain of one copy, and estimates at -0.5 (log2(0.5)) a loss of one copy.\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWe provide the tumor bam, normal bam, the interval list (can also be a bed file) and our reference genome:\n#!/usr/bin/env bash\n\nALIGNDIR=~/project/course_data/alignments\nREFDIR=~/project/course_data/reference\nRESOURCEDIR=~/project/course_data/resources\nVARIANTDIR=~/project/course_data/variants\n\ncnvkit.py batch \"$ALIGNDIR\"/tumor.recal.bam \\\n--normal \"$ALIGNDIR\"/normal.recal.bam \\\n--targets \"$REFDIR\"/exome_regions.bed.interval_list \\\n--fasta \"$REFDIR\"/ref_genome.fa \\\n--annotate \"$RESOURCEDIR\"/refFlat.txt \\\n--output-reference \"$VARIANTDIR\"/reference.cnn \\\n--output-dir \"$VARIANTDIR\"/cnvkit/ \\\n--processes 4 \\\n--scatter \\\n--diagram\nAfter running cnvkit, multiple files are created in ~/project/course_data/variants/cnvkit. The scatter plot is typically interesting to investigate at first:\n\nHere we see that there is evidence for both losses and gains on both chromosomes."
  },
  {
    "objectID": "quality_control.html",
    "href": "quality_control.html",
    "title": "Setup & quality control",
    "section": "",
    "text": "Download the presentation"
  },
  {
    "objectID": "quality_control.html#presentation",
    "href": "quality_control.html#presentation",
    "title": "Setup & quality control",
    "section": "",
    "text": "Download the presentation"
  },
  {
    "objectID": "quality_control.html#exercises",
    "href": "quality_control.html#exercises",
    "title": "Setup & quality control",
    "section": "Exercises",
    "text": "Exercises\n\nFirst login\nIf you are participating in this course with a teacher, you have received a link and a password. Copy-paste the link (including the port, e.g.: http://12.345.678.91:10002) in your browser. This should result in the following page:\n\n\n\n\n\n\n\nNote\n\n\n\nThe link gives you access to a web version of Visual Studio Code. This is a powerful code editor that you can also use as a local application on your computer.\n\n\nType in the password that was provided to you by the teacher. Now let’s open the terminal. You can do that with ++ctrl+grave++. Or by clicking Application menu &gt; Terminal &gt; New Terminal:\n\nFor a.o. efficiency and reproducibility it makes sense to execute your commands from a script. With use of the ‘new file’ button:\n\n\n\nSetup\nWe will start the exercises with pre-aligned bam files. To start, download and extract the course_data folder:\nwget https://cancer-variants-training.s3.eu-central-1.amazonaws.com/course_data.tar.gz\ngunzip course_data.tar.gz\nrm course_data.tar.gz\nNow, check out the directory course_data and see what’s in there (e.g. with tree):\ncourse_data\n├── alignments\n│   ├── normal.recal.bai\n│   ├── normal.recal.bam\n│   ├── tumor.recal.bai\n│   └── tumor.recal.bam\n├── reference\n│   ├── exome_regions.bed\n│   ├── exome_regions.bed.interval_list\n│   ├── ref_genome.dict\n│   └── ref_genome.fa\n└── resources\n    ├── 1000G_phase1.snps.high_confidence.hg38.subset.vcf.gz\n    ├── 1000G_phase1.snps.high_confidence.hg38.subset.vcf.gz.tbi\n    ├── 1000g_pon.hg38.subset.vcf.gz\n    ├── 1000g_pon.hg38.subset.vcf.gz.tbi\n    ├── af-only-gnomad.hg38.subset.vcf.gz\n    ├── af-only-gnomad.hg38.subset.vcf.gz.tbi\n    ├── Mills_and_1000G_gold_standard.indels.hg38.subset.vcf.gz\n    ├── Mills_and_1000G_gold_standard.indels.hg38.subset.vcf.gz.tbi\n    └── refFlat.txt\n\n4 directories, 17 files\nShowing us that we have three directories:\n\nalignments: containing bam files of tumor and normal\nreference: containing the genome fasta file and target intervals\nresources: containing variant files (vcf) from amongst other the 1000 genomes project and gnomAD.\n\nThe dataset we’re working with is prepared by the developers of the Precision medicine bioinformatics course by the Griffith lab. It is whole exome sequencing data of cell lines derived from a tumor of triple negative breast cancer (HCC1395) and derived from normal tissue (HCC1395 BL).\nYou are strongly encouraged to your work with scripts during the course, which you store in the directory scripts. Therefore create a scripts directory:\ncd ~/project/\nmkdir scripts \n\n\nQuality control of the bam files\nFirst we use the information in the header to get information about the contents of the bam file and how it was generated. In order to use the tools installed for this course activate the mamba environment (do this every time you open a new terminal):\nmamba activate ngs-tools \n\n\n\n\n\n\nExercise\n\n\n\nCheck out the contents of the headers of the bam files with samtools view -H, and answer the following questions:\n\nHow is the bam file sorted?\nWhich chromosomes were used as reference?\nHow many read groups are in there, what is the readgroup ID and what is the sample name?\nWhich aligner was used?\nIf there are duplicates in there, how are they marked?\nWhich other programs were run to create the bam file?\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nTo get information on the bam header we run\ncd ~/project/course_data/alignments\nsamtools view -H normal.recal.bam\nWhich returns:\n@HD     VN:1.6  SO:coordinate\n@SQ     SN:chr6 LN:170805979\n@SQ     SN:chr17        LN:83257441\n@RG     ID:HWI-ST466.C1TD1ACXX.normal   LB:normal       PL:ILLUMINA     SM:normal       PU:HWI-ST466.C1TD1ACXX\n@PG     ID:bwa  PN:bwa  VN:0.7.17-r1188 CL:bwa mem /config/data/reference//ref_genome.fa /config/data/reads/normal_R1.fastq.gz /config/data/reads/normal_R2.fastq.gz\n@PG     ID:samtools     PN:samtools     PP:bwa  VN:1.21 CL:samtools sort\n@PG     ID:samtools.1   PN:samtools     PP:samtools     VN:1.21 CL:samtools view -bh\n@PG     ID:MarkDuplicates       VN:Version:4.5.0.0      CL:MarkDuplicates --INPUT /config/data/alignments/normal.rg.bam --OUTPUT /config/data/alignments/normal.rg.md.bam --METRICS_FILE /config/data/alignments/marked_dup_metrics_normal.txt ...   PN:MarkDuplicates\n@PG     ID:GATK ApplyBQSR       VN:4.5.0.0      CL:ApplyBQSR --output /config/project/data/alignments/.recal.bam --bqsr-recal-file /config/project/data/alignments/normal.bqsr.recal.table --input /config/project/data/alignments/normal.rg.md.bam ...        PN:GATK ApplyBQSR\n@PG     ID:samtools.2   PN:samtools     PP:samtools.1   VN:1.21 CL:samtools view -H tumor.recal.bam\n\nFrom the @HD tag, we can see that the bam file is sorted by coordinate.\nWe have two lines starting with @SQ, which gives us information about the reference used. The reference genome used contains chromosomes 6 and 17.\nWe have one line starting with @RG. Specifying there is a read group with ID HWI-ST466.C1TD1ACXX.normal and sample name (SM) normal.\nIn order to know which programs were run to generate this bam file, we can use the @PG tags. Here, we see that the aligner used was bwa mem\nThe duplicates were marked with MarkDuplicates.\nTo sort and compress samtools sort and samtools view were used. For base quality score recalibration (BQSR) GATK ApplyBQSR was used.\n\n\n\n\nNow we extract information from the alignments themselves. We first have a look at few alignments and then get a summary of the alignments with samtools flagstat.\n\n\n\n\n\n\nExercise\n\n\n\nCheck out the first few alignments with samtools view and head.\n\nWhat is likely the read length used?\nAre the reads single-end or paired-end?\nAre the first reads tagged with the readgroup ID?\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe command:\nsamtools view normal.recal.bam | head -3\nReturns the first three alignments:\nHWI-ST466:135068617:C1TD1ACXX:7:1114:9733:82689 163     chr6    60001   60      100M    =       60106   205     GATCTTATATAACTGTGAGATTAATCTCAGATAATGACACAAAATATAGTGAAGTTGGTAAGTTATTTAGTAAAGCTCATGAAAATTGTGCCCTCCATTC     ;B@EDB@A@A@DDDGBGBFCBC?DBEEGCGCAADAGCECDCDDDBABAGBECEGCBHH@?EGBCBCDDBHBAEEHGDFBBHBDDDBCHBGEFFEGEDBBG     MC:Z:100M       MD:Z:100        PG:Z:MarkDuplicates     RG:Z:HWI-ST466.C1TD1ACXX.normal NM:i:0  AS:i:100        XS:i:0\nHWI-ST466:135068617:C1TD1ACXX:7:1303:2021:90688 99      chr6    60001   60      100M    =       60104   203     GATCTTATATAACTGTGAGATTAATCTCAGATAATGACACAAAATATAGTGAAGTTGGTAAGTTATTTAGTAAAGCTCATGAAAATTGTGCCCTCCATTC     &gt;A@FDB@A?@&gt;DDCE@FAF@?BAC&gt;ECFCGBAADBEADBDCDDD@@A@FAFADD?ABF@@EF?@ABCDAFB?DCGEBEB@EBCDCBCHBFEFFDGFCBBG     MC:Z:100M       MD:Z:100        PG:Z:MarkDuplicates     RG:Z:HWI-ST466.C1TD1ACXX.normal NM:i:0  AS:i:100        XS:i:0\nHWI-ST466:135068617:C1TD1ACXX:7:2304:7514:30978 113     chr6    60001   60      2S98M   =       61252   1194    TAGATCTTATATAACTGTGAGATTAATCTCAGATAATGACACAAAATATAGTGAAGTTGGTAAGTTATTTAGTAAAGCTCATGAAAATTGTGCCCTCCAT     &gt;DHABFEACBBBCBGCECHEGBEACBDHCGCHCBDBBFAEAGBCCB@BAEECGBEEDBED&gt;@EDDABDDADE@CBDFFBFBCFCCBADBDBDFFFAFF?@     MC:Z:60S40M     MD:Z:98 PG:Z:MarkDuplicates     RG:Z:HWI-ST466.C1TD1ACXX.normal NM:i:0  AS:i:98 XS:i:0\n\nAt the CIGAR strings we see 100M and 2S98M, meaning that the original read had 100 base pairs. So it’s likely a read length of 100 bp has been used.\nThis question might be a bit more challenging. In the 5th column we see an equal sign (=). This shows that the mate is mapped to same chromsome, so suggesting we are working with paired-end reads. Secondly, at the @PG header tag, we saw that bwa mem took two fastq files (normal_R1.fastq.gz and normal_R2.fastq.gz) as input. Lastly, we can use the sam flags in the second column to figure that out. If you paste the first flag, 163, in the explain sam flags website, we can see that the read is paired.\nYes, the read group tag starts with RG, and is specified for all three alignments.\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nCreate a script called 01_samtools_flagstat.sh and store it in ~/project/scripts. Use samtools flagstat to summarize the alignments in both bam files. How many reads are in the bam files? And how many alignments are marked as duplicate?\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\ncd ~/project/course_data/alignments\n\nfor sample in tumor normal\ndo\n    samtools flagstat \"$sample\".recal.bam &gt; \"$sample\".recal.bam.flagstat\ndone\nreturns for normal.recal.bam:\n12744793 + 0 in total (QC-passed reads + QC-failed reads)\n12733034 + 0 primary\n0 + 0 secondary\n11759 + 0 supplementary\n1397598 + 0 duplicates\n1397598 + 0 primary duplicates\n12671529 + 0 mapped (99.43% : N/A)\n12659770 + 0 primary mapped (99.42% : N/A)\n12733034 + 0 paired in sequencing\n6366517 + 0 read1\n6366517 + 0 read2\n12515974 + 0 properly paired (98.30% : N/A)\n12586532 + 0 with itself and mate mapped\n73238 + 0 singletons (0.58% : N/A)\n20414 + 0 with mate mapped to a different chr\n13194 + 0 with mate mapped to a different chr (mapQ&gt;=5)\nShowing us that we have 12,744,793 reads, and all those were paired. Of the alignments, 1,397,598 were marked as duplicate. If we do the same for the tumor bam file we see that it has 16,674,562 reads and 1,871,521 alignment marked as duplicate.\n\n\n\nSo, all looks good until now. We have many reads and high alignment rates. The bam files seem to be ready for variant analysis, because they have read groups, duplicates are marked and they are sorted by coordinate. However, since we are working with whole exome sequencing (WES) data, we would like to know whether the reads align to the target regions and what kind of coverage we have. For this, we use gatk CollectHsMetrics.\n\n\n\n\n\n\nExercise\n\n\n\nCreate a script called 02_gatk_collecthsmetrics.sh in ~/project/scripts to run gatk CollectHsMetrics on the two bam files. Here’s an example:\nALIGNDIR=~/project/course_data/alignments\nREFDIR=~/project/course_data/reference\nRESOURCEDIR=~/project/course_data/resources\n\nfor sample in tumor normal\ndo\n    gatk CollectHsMetrics \\\n    -I \"$ALIGNDIR\"/\"$sample\".recal.bam \\\n    -O \"$ALIGNDIR\"/\"$sample\".recal.bam_hs_metrics.txt \\\n    -R \"$REFDIR\"/ref_genome.fa \\\n    --BAIT_INTERVALS \"$REFDIR\"/exome_regions.bed.interval_list \\\n    --TARGET_INTERVALS \"$REFDIR\"/exome_regions.bed.interval_list\ndone \nThe produced reports are not so easy to read. To parse the metrics file, we run multiqc on the directory:\ncd ~/project/course_data/alignments\nmultiqc .\nDownload the multiqc report (multiqc_report.html) by right-clicking on the file and select ‘Download’. Check out the hybrid-selection metrics. How did the hybrid capture go? Are most bases on-target? What kind of coverages can we expect in the target regions?\n\n\n\n\n\n\n\n\nNote\n\n\n\nYou can find the documentation on the different metrics here. Note that the descriptions of the metrics are not always correct. The metrics with ON_BAIT contain information including duplicates, while ON_TARGET without duplicates. This has been an issue since 2020, and hasn’t been worked on unfortunately.\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWe see that we have a fold enrichment of around 22 and about 45% usable bases on-target. About 90% were ‘selected bases’, which means bases aligning within 250 bp of the target region. We’re looking at a de-duplicated coverage of 84x for the normal sample and 114.3x for the tumor sample. So, on average, we seem to have acceptable coverages for both samples."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "SIB course cancer variant analysis",
    "section": "",
    "text": "Flavio Lombardo ORCiD\nGeert van Geest ORCiD"
  },
  {
    "objectID": "index.html#teachers-and-authors",
    "href": "index.html#teachers-and-authors",
    "title": "SIB course cancer variant analysis",
    "section": "",
    "text": "Flavio Lombardo ORCiD\nGeert van Geest ORCiD"
  },
  {
    "objectID": "index.html#attribution",
    "href": "index.html#attribution",
    "title": "SIB course cancer variant analysis",
    "section": "Attribution",
    "text": "Attribution\nParts of this course are inspired by the Precision medicine course, from the Griffith lab."
  },
  {
    "objectID": "index.html#license-copyright",
    "href": "index.html#license-copyright",
    "title": "SIB course cancer variant analysis",
    "section": "License & copyright",
    "text": "License & copyright\nLicense: CC BY 4.0\nCopyright: SIB Swiss Institute of Bioinformatics"
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "SIB course cancer variant analysis",
    "section": "Overview",
    "text": "Overview\nCancer is a disease of the genome. Mutations of genes that regulate cell proliferation and cell death result in uncontrolled growth eventually causing symptoms. During cancer progression, mutations build up that not only affect cell growth, but also can suppress the immune system, increase the chance of metastases and promote genome instability leading to additional malignant mutations.\nCharacterizing the mutations of malignant tissue has been instrumental for the development of the diagnosis, prognosis and treatment of cancer in the last decades. Cancer is a highly heterogeneous disease, and by knowing the type of mutations, we have a better understanding of the nature of tumors, and can apply precision medicine approaches, like targeted drug and immune therapy.\nCancer variants are somatic, which means that they exist in only a part of the cells in the tissue. Even in a sample of a solid tumor, only a part of the cells contains the driver mutations. This makes analysis of cancer variants more challenging than inherited variants, where we assume (almost) all cells have the same genome.\nIn this course, you will learn the concepts of calling somatic variants from next generation sequencing data, and the basics of performing cancer variant annotation. The practical work will be mainly based on the GATK4 (Mutect2) pipeline and Ensembl’s Variant Effect Predictor (VEP)."
  },
  {
    "objectID": "index.html#audience",
    "href": "index.html#audience",
    "title": "SIB course cancer variant analysis",
    "section": "Audience",
    "text": "Audience\nThis intermediate level course is addressed to researchers and clinicians who work with cancer biology and want to get started with performing somatic variant analysis and interpretation of the results."
  },
  {
    "objectID": "index.html#learning-outcomes",
    "href": "index.html#learning-outcomes",
    "title": "SIB course cancer variant analysis",
    "section": "Learning outcomes",
    "text": "Learning outcomes\nAt the end of the course, the participants should be able to:\n\nUnderstand the difference between germline and somatic variants and the implication of computational analysis\nPerform a somatic variant analysis on a paired sample (tumor – normal) with GATK4\nPerform a somatic variant annotation with VEP and use the results to filter possible high-impact mutations in the cancer genome"
  },
  {
    "objectID": "course_schedule.html",
    "href": "course_schedule.html",
    "title": "Course schedule",
    "section": "",
    "text": "Note\n\n\n\nApart from the starting time the time schedule is indicative. Because we can not plan a course by the minute, in practice the time points will deviate."
  },
  {
    "objectID": "course_schedule.html#day-1",
    "href": "course_schedule.html#day-1",
    "title": "Course schedule",
    "section": "Day 1",
    "text": "Day 1\n\n\n\nblock\nstart\nend\nsubject\n\n\n\n\nintroduction\n9:00 AM\n10:00 AM\nIntroduction - lecture\n\n\nblock 1\n10:00 AM\n10:30 AM\nSetup and quality control - exercises\n\n\n\n10:30 AM\n11:00 AM\nBREAK\n\n\nblock 2\n11:00 AM\n12:00 PM\nVariant calling - exercises\n\n\n\n12:00 PM\n1:00 PM\nBREAK\n\n\nblock 3\n1:00 PM\n1:45 PM\nVariant annotation - lecture\n\n\nblock 4\n1:45 PM\n3:00\nVariant annotation - exercises\n\n\n\n3:00 PM\n3:30 PM\nBREAK\n\n\nblock 4\n3:30 PM\n4:10 PM\nVariant annotation - exercises\n\n\nblock 5\n4:10 PM\n5:00 PM\nVisualization - exercises"
  },
  {
    "objectID": "precourse_preparations.html",
    "href": "precourse_preparations.html",
    "title": "Precourse preparations",
    "section": "",
    "text": "Participants should have knowledge in NGS techniques, quality control and alignment to a reference genome, and detection of genomic variants from read alignment to variant calling and annotation.\nThe competences and knowledge levels required correspond to those taught in courses such as: NGS - Quality Control, Alignment, Visualisation and NGS-Genome Variant Analysis.\nParticipants should have a basic understanding of working with command line tools on Unix-based systems. You can test your skills with Unix with the quiz here. If you do not feel comfortable with UNIX commands, please take our Unix fundamentals e-learning module.\n\n\n\nParticipants should have their own computer with a browser installed (e.g. chrome, firefox, edge), and can access http websites. Test it here: http://httpforever.com/."
  },
  {
    "objectID": "precourse_preparations.html#prerequisites",
    "href": "precourse_preparations.html#prerequisites",
    "title": "Precourse preparations",
    "section": "",
    "text": "Participants should have knowledge in NGS techniques, quality control and alignment to a reference genome, and detection of genomic variants from read alignment to variant calling and annotation.\nThe competences and knowledge levels required correspond to those taught in courses such as: NGS - Quality Control, Alignment, Visualisation and NGS-Genome Variant Analysis.\nParticipants should have a basic understanding of working with command line tools on Unix-based systems. You can test your skills with Unix with the quiz here. If you do not feel comfortable with UNIX commands, please take our Unix fundamentals e-learning module.\n\n\n\nParticipants should have their own computer with a browser installed (e.g. chrome, firefox, edge), and can access http websites. Test it here: http://httpforever.com/."
  },
  {
    "objectID": "variant_annotation.html",
    "href": "variant_annotation.html",
    "title": "Variant annotation",
    "section": "",
    "text": "VEP is a powerful and flexible tool for annotating, analyzing, and prioritizing genomic variants. It is particularly useful in cancer genomics, where understanding the functional impact of somatic mutations is crucial for research and clinical applications. We can answer questions like:\n\nHow damaging is a certain somatic mutation (according to reference databases)\nWhat is the impact of this mutation in the particular cancer type of study\nIs the mutation known for that cancer?\nIs there a relation with a certain mutation and a chemotherapeutic (or a class of them)"
  },
  {
    "objectID": "variant_annotation.html#key-concepts",
    "href": "variant_annotation.html#key-concepts",
    "title": "Variant annotation",
    "section": "Key Concepts",
    "text": "Key Concepts\n\nInstall VEP\n\n\n\n\n\n\nImportant\n\n\n\n# Installing Conda #https://docs.anaconda.com/miniconda/\nmkdir -p ~/miniconda3\nwget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh\nbash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3\nrm ~/miniconda3/miniconda.sh\nsource ~/miniconda3/bin/activate\nconda init --all\n\n# Using Conda\nconda create -n vep samtools python=3.10 ensembl-vep=113\n# conda install -c bioconda ensembl-vep=113 # if installing in current env\n\n# Activate VEP's env\nconda activate vep\n\n# Plugins installation\n# vep_install -a p --PLUGINS all\n\n\n\n\n\n\n\n\nNote\n\n\n\nInstead of conda you could try installing mamba. If you are on Unix-based system this is simple. mamba\n\n\n\n\nTranscript Selection\nVEP can report consequences for all transcripts overlapping a variant. However, this often results in multiple annotations per variant. Several approaches are available to handle this:\n\n--pick: Selects one consequence per variant based on a predefined hierarchy\n--pick_allele: Selects one consequence per variant allele\n--pick_allele_gene: Selects one consequence per variant allele per gene\n--per_gene: Selects one consequence per gene\n--flag_pick: Flags the selected consequence while retaining others\n\n\n\nConsequence Priority\nVEP ranks consequences by severity:\n\nTranscript ablation\nSplice acceptor/donor variant\nStop gained\nFrameshift variant\nStop lost\nStart lost\nTranscript amplification\nInframe insertion/deletion\nMissense variant\nProtein altering variant"
  },
  {
    "objectID": "variant_annotation.html#practical-exercises",
    "href": "variant_annotation.html#practical-exercises",
    "title": "Variant annotation",
    "section": "Practical Exercises",
    "text": "Practical Exercises\nIn case that you do not have the Mutect2 call and/or the CNVkit call, you can obtain those from here. In this folder there are also a README.md and some folders containing preprocessed data for the addional resources that we will use with Ensembl-VEP.\n\n\n\n\n\n\nBasic VEP Analysis\n\n\n\nObjective: Annotate a small VCF file and understand the basic output format.\nInput Data:\n##fileformat=VCFv4.2\n#CHROM    POS    ID    REF    ALT    QUAL    FILTER    INFO\nchr7    55242465    rs121913529    A    T    .    PASS    .\nchr17    7577121    rs28934578    C    T    .    PASS    .\nchr13    32936646    rs28897743    C    T    .    PASS    .\nchr17    7674894    rs28934574    G    A    .    PASS    .\nchr13    32914438    rs80357090    T    C    .    PASS    .\nchr17    41245466    rs28897686    G    A    .    PASS    .\nchr3    178936091    rs63751289    G    A    .    PASS    .\nchr10    89624230    rs61751507    G    A    .    PASS    .\nchr11    108098576    rs386833395    G    A    .    PASS    .\nchr4    55141055    rs1800744    A    G    .    PASS    .\nchr1    11190510    rs6603781    G    A    .    PASS    .\nchr7    140453136    rs121913530    A    T    .    PASS    .\nchr5    112175770    rs121913343    C    T    .    PASS    .\nTask: Annotate these variants using VEP and identify which genes are affected.\n\n\n\n\n\n\n\n\nCommand\n\n\n\n\n\nVEP can be provided with a VCF file as an input (or vcf.gz + index) file or other formats, see documentation here \nvep -i input.vcf --cache --species homo_sapiens \\\n--assembly GRCh38 --offline --format vcf \\\n--symbol --force_overwrite --domains \\\n--sift b --polyphen b \\\n--output_file output.txt\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n# 1. First, create a script that will generate our VCF file. \n# Copy this code into a new file named `create_vcf.sh`\n# with the command `nano create_vcf.sh`:\n\n#!/usr/bin/env bash\n\necho -e '##fileformat=VCFv4.2\n##INFO=&lt;ID=AF,Number=A,Type=Float,Description=\"Allele Frequency\"&gt;\n#CHROM\\tPOS\\tID\\tREF\\tALT\\tQUAL\\tFILTER\\tINFO\nchr7\\t55242465\\trs121913529\\tA\\tT\\t.\\tPASS\\t.\nchr17\\t7577121\\trs28934578\\tC\\tT\\t.\\tPASS\\t.\nchr13\\t32936646\\trs28897743\\tC\\tT\\t.\\tPASS\\t.\nchr17\\t7674894\\trs28934574\\tG\\tA\\t.\\tPASS\\t.\nchr13\\t32914438\\trs80357090\\tT\\tC\\t.\\tPASS\\t.\nchr17\\t41245466\\trs28897686\\tG\\tA\\t.\\tPASS\\t.\nchr3\\t178936091\\trs63751289\\tG\\tA\\t.\\tPASS\\t.\nchr10\\t89624230\\trs61751507\\tG\\tA\\t.\\tPASS\\t.\nchr11\\t108098576\\trs386833395\\tG\\tA\\t.\\tPASS\\t.\nchr4\\t55141055\\trs1800744\\tA\\tG\\t.\\tPASS\\t.\nchr1\\t11190510\\trs6603781\\tG\\tA\\t.\\tPASS\\t.\nchr7\\t140453136\\trs121913530\\tA\\tT\\t.\\tPASS\\t.\nchr5\\t112175770\\trs121913343\\tC\\tT\\t.\\tPASS\\t.' &gt; cancer_variants.vcf\n\n# 2. Make the script executable:\nchmod +x create_vcf.sh\n\n# 3. Run the script:\n./create_vcf.sh\n\n# 4. Verify the file was created correctly:\n# Check the content\ncat cancer_variants.vcf\n\n# Make sure you have 13 variants\ngrep -v '^#' cancer_variants.vcf | wc -l  # Should show 13\n\n# Run VEP ~&lt; 5min\nvep -i cancer_variants.vcf -cache \\\n    --species homo_sapiens \\\n    --offline \\\n    --force_overwrite \\\n    --assembly GRCh38 \\\n    --format vcf \\\n    --symbol \\\n    --sift b \\\n    --polyphen b \\\n    --pick \\\n    --domains \\\n    --output_file output.txt\n\n# Some of the variants affect:\n\n## VEP command-line: vep --assembly GRCh38 --cache --database 0 --force_overwrite --format vcf --input_file cancer_variants.vcf --offline --output_file output.txt --pick --symbol\n#Uploaded_variation Location    Allele  Gene    Feature Feature_type    Consequence cDNA_position   CDS_position    Protein_position    Amino_acids Codons  Existing_variation  Extra\nrs121913529 chr7:55242465   T   ENSG00000280890 ENST00000626532 Transcript  intron_variant,non_coding_transcript_variant    -   -   -   -   -   -   IMPACT=MODIFIER;STRAND=-1;SYMBOL=ELDR;SYMBOL_SOURCE=HGNC;HGNC_ID=HGNC:49511\nrs28934578  chr17:7577121   T   ENSG00000161960 ENST00000293831 Transcript  missense_variant    597 580 194 D/Y Gac/Tac -   IMPACT=MODERATE;STRAND=1;SYMBOL=EIF4A1;SYMBOL_SOURCE=HGNC;HGNC_ID=HGNC:3282\nrs28897743  chr13:32936646  T   -   -   -   intergenic_variant  -   -   -   -   -   -   IMPACT=MODIFIER\nrs28934574  chr17:7674894   A   ENSG00000141510 ENST00000269305 Transcript  stop_gained 779 637 213 R/* Cga/Tga -   IMPACT=HIGH;STRAND=-1;SYMBOL=TP53;SYMBOL_SOURCE=HGNC;HGNC_ID=HGNC:11998\nrs28897686  chr17:41245466  A   ENSG00000241595 ENST00000334109 Transcript  upstream_gene_variant   -   -   -   -   -   -   IMPACT=MODIFIER;DISTANCE=4221;STRAND=1;SYMBOL=KRTAP9-4;SYMBOL_SOURCE=HGNC;HGNC_ID=HGNC:18902\nrs28934574 from this example is a TP53 stop gained mutation commonly found in cancer.\nYou can try to run without --pick and --everything see what happens.\n\n\n\nAfter running the command you will also notice a output.txt_summary.html that will show some statistics on the annotation process. If you tried running --everything or -e this is a shortcut for the following options:\n\n\n\n\n\n\n--everything\n\n\n\n\n\n--sift b, --polyphen b, --ccds, --hgvs, --symbol, --numbers, --domains, --regulatory, --canonical, --protein, --biotype, --af, --af_1kg, --af_esp, --af_gnomade, --af_gnomadg, --max_af, --pubmed, --uniprot, --mane, --tsl, --appris, --variant_class, --gene_phenotype, --mirna \nThis an example of the highput from the TP53 mutation\n\n\n\n\n\n\n\n\nField\nValue\nDescription\n\n\n\n\nUploaded Variation\nrs28934574\ndbSNP identifier\n\n\nLocation\nchr17:7674894\nGenomic coordinates (GRCh38)\n\n\nAllele\nA\nAlternative allele\n\n\nGene\nENSG00000141510\nEnsembl gene ID for TP53\n\n\nTranscript\nENST00000455263\nEnsembl transcript ID\n\n\nFeature Type\nTranscript\nType of genomic feature affected\n\n\nConsequence\nstop_gained\nCreates premature stop codon\n\n\ncDNA Position\n770\nPosition in the cDNA\n\n\nCDS Position\n637\nPosition in the coding sequence\n\n\nProtein Position\n213\nPosition in the protein\n\n\nAmino Acids\nR/*\nChange from Arginine to stop codon\n\n\nCodons\nCga/Tga\nCodon change\n\n\nImpact\nHIGH\nSeverity of variant impact\n\n\nSymbol\nTP53\nHGNC gene symbol\n\n\nBiotype\nprotein_coding\nType of transcript\n\n\nCCDS\nCCDS45605.1\nConsensus CDS identifier\n\n\nUniProt\nP04637.305\nUniProt protein identifier\n\n\nHGVSc\nENST00000455263.6:c.637C&gt;T\nCoding sequence change in HGVS notation\n\n\nHGVSp\nENSP00000398846.2:p.Arg213Ter\nProtein change in HGVS notation\n\n\nClinical Significance\npathogenic\nClinical interpretation\n\n\ngnomAD AF\n1.368e-06\nAllele frequency in gnomAD\n\n\nMaximum AF\n1.656e-05\nMaximum allele frequency observed\n\n\n\n\n\n\nYou can have a look at the documentation to learn more about VEP’s many options here\n\n\n\n\n\n\nDamage prediction tools\n\n\n\n\n\n\nSIFT: Based on sequence homology and physical properties of amino acids\nPolyPhen: Combines sequence-based features with structural information\n\n\n\n\n\nMutect2 results annotation\nIn the example above we used an example to undestand how to run VEP and some different arguments that can make a big difference in the output generated and the information provided.\nIf we use the results coming from the somatic call from the WES of chr6 and chr17 we get a table of variants. These results can be enriched with annotations. Let’s use VEP to annotate this file\nExtract from the resulting Mutect2 somatic call\n##fileformat=VCFv4.2 \n#CHROM  POS     ID      REF  ALT   QUAL  FILTER  INFO \nchr17   745040    .   G   T   .   PASS\nchr17   1492466   .   C   T   .   PASS\nchr17   2364457   .   T   G   .   PASS\nchr17   3433669   .   G   T   .   PASS\nchr17   4545725   .   T   C   .   PASS\nchr17   4934441   .   G   T   .   PASS\nchr17   5007047   .   C   T   .   PASS\nchr17   7560755   .   G   A   .   PASS\nchr17   7588500   .   G   C   .   PASS\nchr6    325357    .   G   A   .   PASS\nchr6    325783    .   G   C   .   PASS\nchr6    325901    .   G   A   .   PASS\nchr6    1916336   .   G   A   .   PASS\nchr6    2674999   .   A   C   .   PASS\nchr6    2834013   .   C   G   .   PASS\nchr6    2840548   .   C   T   .   PASS\nchr6    3723708   .   C   G   .   PASS"
  },
  {
    "objectID": "variant_annotation.html#using-vep-to-annotate-mutect2-variants",
    "href": "variant_annotation.html#using-vep-to-annotate-mutect2-variants",
    "title": "Variant annotation",
    "section": "Using VEP to annotate Mutect2 variants",
    "text": "Using VEP to annotate Mutect2 variants\nThe somatic variant call can be annotated with this command\nvep -i somatic.filtered.PASS.vcf.gz --cache --species homo_sapiens \\\n--assembly GRCh38 --offline --format vcf \\\n--symbol --force_overwrite -e \\\n--output_file chr6ch17_mutect2_annotated.txt\n\n\n\n\n\n\nOutput to VCF\n\n\n\nWhat if the output of this file should be formatted as vcf instead? You can check VEP’s documentation here\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWith the option --output_file you can use vcf. After you can compress the VCF bgzip &lt;output_file.vcf&gt; and then you can index it tabix -p vcf &lt;output_file.vcf.gz&gt;. If you see VEP’s documentation there is an option to skip bgzip and instead incorporating it directly in VEP, which will be doing the compression for you --compress_output bgzip in the call. Afterwards you still need to index the file.\n\n\n\nInteresting results: We will obtain a file with many annotations.\n\nchr6_1930220_GA/TT   chr6:1930220-1930221    TT  ENSG00000112699 ENST00000380815 Transcript  stop_gained 836-837 653-654 218 F/* tTC/tAA -   IMPACT=HIGH;STRAND=-1;SYMBOL=GMDS;SYMBOL_SOURCE=HGNC;HGNC_ID=HGNC:4369\n\n\n\n\n\n\n\n\n\n\n\n\nImpact\nGene\nLocation\nConsequence\nChange\nDetails\n\n\n\n\nHIGH\nGMDS\nchr6:1930220\nstop_gained\nF→*\nCreates premature stop codon\n\n\n\n\n\n\n\n\n\nAnd other interesting variants\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImpact\nGene\nLocation\nConsequence\nChange\nDetails\n\n\n\n\nHIGH\nSERPINB1\nchr6:2834013\nsplice_acceptor_variant\nC&gt;G\nAffects splice site\n\n\nMODERATE\nOR1E2\nchr17:3433669\nmissense_variant\nP→H\nPosition 58\n\n\nMODERATE\nPLD2\nchr17:4818362\ninframe_deletion\nVDRILK→V\n15bp deletion\n\n\nLOW\nGEMIN4\nchr17:745040\nsynonymous_variant\nL→L\nNo amino acid change\n\n\nMODIFIER\nDUSP22\nchr6:325357\nintron_variant\nG&gt;A\nWithin intron\n\n\n\n\n\n\n\n\n\n\n\n\nPerformance Trick\n\n\n\nCan you run the same command as before adding --fork 2, do you note any difference?\nvep -i somatic.filtered.PASS.vcf.gz --cache --species homo_sapiens \\\n--assembly GRCh38 --offline --format vcf \\\n--symbol --force_overwrite -e --fork 2 \\\n--output_file chr6ch17_mutect2_annotated.txt\n\n\nNow when we anaylize our output file chr6ch17_mutect2_annotated.txt in more details, there are about 160 lines and a lot of information on different transcripts that are related to the mutations found by Mutect2. Let’s say that now we would like to filter only the deleterious predictions and moderate/high impact variants. We can do that in a couple of ways:\nfilter_vep \\\n-i chr6ch17_mutect2_annotated.txt \\\n-o chr6ch17_mutect2_annotated_filtered.txt \\\n--force_overwrite \\\n--filter \"(IMPACT is HIGH or IMPACT is MODERATE) or (SIFT match deleterious or PolyPhen match probably_damaging)\"\n\n\n\n\n\n\nCaution\n\n\n\nin this line --filter \"(IMPACT is HIGH or IMPACT is MODERATE) or (SIFT match deleterious or PolyPhen match probably_damaging)\" consider that there is a difference in saying or or and as the latter is much more stringent and it would look only for variants whose prediction is in agreement.\n\n\nBut what if we want more information on the cancer mutations, can we integrate other databases to VEP? Yes we can. This can be useful prior to filtering to find additional consensus on potential interesting targets.\n\n\n\n\n\n\nCancer-Specific Annotation\n\n\n\nObjective: Add cancer-specific annotations using ClinVar and filter for potentially pathogenic variants.\nTask: Enhance the previous analysis by:\n\nAdding ClinVar annotations\nFiltering for HIGH/MODERATE impact variants\nCreating a summary of mutation types\n\nYou can download from here\n# Download latest ClinVar VCF\nwget https://ftp.ncbi.nlm.nih.gov/pub/clinvar/vcf_GRCh38/clinvar.vcf.gz\nwget https://ftp.ncbi.nlm.nih.gov/pub/clinvar/vcf_GRCh38/clinvar.vcf.gz.tbi\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n# Download ClinVar VCF\n\n# Run VEP with cancer-specific annotations\nvep -i somatic.filtered.PASS.vcf.gz \\\n    --cache \\\n    --assembly GRCh38 \\\n    --format vcf \\\n    --force_overwrite \\\n    --fork 2 \\\n    --everything \\\n    --custom clinvar.vcf.gz,ClinVar,vcf,exact,0,CLNSIG,CLNREVSTAT,CLNDN \\\n    --output_file chr6ch17_mutect2_annotated_with_clinVar.txt\n\n# Filter results\nfilter_vep \\\n-i chr6ch17_mutect2_annotated_with_clinVar.txt \\\n-o chr6ch17_mutect2_annotated_with_clinVar_filtered.txt \\\n--force_overwrite \\\n--filter \"(IMPACT is HIGH or IMPACT is MODERATE) or \\\n(SIFT match deleterious or PolyPhen match probably_damaging) or \\\n(ClinVar_CLNSIG match pathogenic)\"\n\n# Generate summary (using simple grep/awk commands)\necho \"Mutation Type Summary:\" &gt; summary.txt\ngrep -v \"#\" chr6ch17_mutect2_annotated_with_clinVar_filtered.txt | cut -f7 | sort | uniq -c &gt;&gt; summary.txt\nThe possible values for ClinVar_CLNSIG include:\n\nPathogenic - Strong evidence the variant causes disease\nLikely_pathogenic - Evidence suggests it is probably disease-causing\nUncertain_significance (VUS) - Not enough evidence to classify either way\nLikely_benign - Evidence suggests it is probably not disease-causing\nBenign - Strong evidence the variant is not disease-causing\nConflicting_interpretations_of_pathogenicity - Different submitters disagree\nNot_provided - No interpretation was provided\nDrug_response - Affects response to medications\nOther - Other interpretations\n\n\n\n\nThe clinvar data provided us with more information coming from curated databases, and for some variants we can have multiple levels of consensus (however this is not a garantee of pathogenicity), but there are many other additional databases that one can try. However not all the databases have the same licensing, therefore each of the integrated datasets should be checked. For example COSMIC databases can be accessed only after registration, onkoKB as well.  Please do not forget to cite the data that you use and it is important to keep note of the version used."
  },
  {
    "objectID": "variant_annotation.html#advanced-topics",
    "href": "variant_annotation.html#advanced-topics",
    "title": "Variant annotation",
    "section": "Advanced Topics",
    "text": "Advanced Topics\n\nUsing VEP Plugins\nVEP’s functionality can be extended through plugins. Here are some essential plugins for cancer analysis:\n\nREVEL: Rare Exome Variant Ensemble Learner\n\n\nREVEL paper: An Ensemble Method for Predicting the Pathogenicity of Rare Missense Variants\n\n\n\n\n\n\n\nREVEL\n\n\n\n\n\nREVEL\nYou can download here the data (~6.5GB): https://sites.google.com/site/revelgenomics/downloads or https://zenodo.org/records/7072866\nunzip revel-v1.3_all_chromosomes.zip\ncat revel_with_transcript_ids | tr \",\" \"\\t\" &gt; tabbed_revel.tsv\nsed '1s/.*/#&/' tabbed_revel.tsv &gt; new_tabbed_revel.tsv\nbgzip new_tabbed_revel.tsv\nPrepare for GRCh38\nzcat new_tabbed_revel.tsv.gz | head -n1 &gt; h\nzgrep -h -v ^#chr new_tabbed_revel.tsv.gz | awk '$3 != \".\" ' | sort -k1,1 -k3,3n - | cat h - | bgzip -c &gt; new_tabbed_revel_grch38.tsv.gz\ntabix -f -s 1 -b 3 -e 3 new_tabbed_revel_grch38.tsv.gz\nUsage:\n--plugin REVEL,file=/path/to/revel/data.tsv.gz\n\n\n\n\nAlphaMissense: Deep learning-based predictor\n\n\nAlphaMissense’s Paper: Accurate proteome-wide missense variant effect prediction with AlphaMissense\n\n\n\n\n\n\n\nAlphaMissense\n\n\n\n\n\nAlphaMissense\nDownload link\nPrepare for GRCh38\nwget https://storage.googleapis.com/dm_alphamissense/AlphaMissense_hg38.tsv.gz\ntabix -s 1 -b 2 -e 2 -f -S 1 AlphaMissense_hg38.tsv.gz\nRun it with VEP\n--plugin AlphaMissense,file=/full/path/to/file.tsv.gz\n\n\n\nWe have seen how to run VEP and how to filter the output. Now we can make another call on the Mutect2 output to annotate the variants using a combination of some plugins and some custom databases.\n\n\n\n\n\n\nDamage prediction tools\n\n\n\n\n\n\nREVEL: An ensemble method that integrates multiple prediction tools\nAlphaMissense: Uses deep learning trained on evolutionary data"
  },
  {
    "objectID": "variant_annotation.html#revel-1",
    "href": "variant_annotation.html#revel-1",
    "title": "Variant annotation",
    "section": "REVEL",
    "text": "REVEL\nYou can download here the data (~6.5GB): https://sites.google.com/site/revelgenomics/downloads or https://zenodo.org/records/7072866\nunzip revel-v1.3_all_chromosomes.zip\ncat revel_with_transcript_ids | tr \",\" \"\\t\" &gt; tabbed_revel.tsv\nsed '1s/.*/#&/' tabbed_revel.tsv &gt; new_tabbed_revel.tsv\nbgzip new_tabbed_revel.tsv\nPrepare for GRCh38\nzcat new_tabbed_revel.tsv.gz | head -n1 &gt; h\nzgrep -h -v ^#chr new_tabbed_revel.tsv.gz | awk '$3 != \".\" ' | sort -k1,1 -k3,3n - | cat h - | bgzip -c &gt; new_tabbed_revel_grch38.tsv.gz\ntabix -f -s 1 -b 3 -e 3 new_tabbed_revel_grch38.tsv.gz\nUsage:\n--plugin REVEL,file=/path/to/revel/data.tsv.gz"
  },
  {
    "objectID": "variant_annotation.html#alphamissense-1",
    "href": "variant_annotation.html#alphamissense-1",
    "title": "Variant annotation",
    "section": "AlphaMissense",
    "text": "AlphaMissense\nDownload link\nPrepare for GRCh38\nwget https://storage.googleapis.com/dm_alphamissense/AlphaMissense_hg38.tsv.gz\ntabix -s 1 -b 2 -e 2 -f -S 1 AlphaMissense_hg38.tsv.gz\nRun it with VEP\n--plugin AlphaMissense,file=/full/path/to/file.tsv.gz"
  },
  {
    "objectID": "variant_annotation.html#complex-vep-run",
    "href": "variant_annotation.html#complex-vep-run",
    "title": "Variant annotation",
    "section": "Complex VEP run",
    "text": "Complex VEP run\n\n\n\n\n\n\nComplex VEP run\n\n\n\nObjective: Learn how to comprehensively annotate cancer variants using VEP’s advanced features, plugins, and filtering capabilities to identify potentially pathogenic variants.\nTask: Enhance the previous analysis by:\n\nAdding ClinVar annotations\nAdding REVEL annotations\nAdding population frequencies --af_gnomade (gnomAD data is included in VEP cache)\nAdding plugins (--plugin SpliceRegion, --plugin AlphaMissense, --plugin REVEL)\nFiltering for HIGH/MODERATE impact variants\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nvep -i somatic.filtered.PASS.vcf.gz \\\n    --cache \\\n    --assembly GRCh38 \\\n    --format vcf \\\n    --fork 2 \\\n    --everything \\\n    --af_gnomade \\\n    --force_overwrite \\\n    --plugin SpliceRegion \\\n    --plugin REVEL,file=new_tabbed_revel_grch38.tsv.gz \\\n    --plugin AlphaMissense,file=AlphaMissense_hg38.tsv.gz \\\n    --custom clinvar.vcf.gz,ClinVar,vcf,exact,0,CLNSIG,CLNREVSTAT,CLNDN \\\n    --output_file chr6ch17_mutect2_annotated_with_clinVar_and_plugins.txt\n    \n# Filter the data -&gt; Stringent\nfilter_vep \\\n-i chr6ch17_mutect2_annotated_with_clinVar_and_plugins.txt \\\n-o stringent_filtered.txt \\\n--force_overwrite \\\n--filter \"(IMPACT is HIGH or IMPACT is MODERATE) and \\\n       (REVEL &gt;= 0.75 or \\\n        am_class = 'likely_pathogenic' or \\\n        SIFT = 'deleterious' and PolyPhen = 'probably_damaging')\"\n          \n# Filter the data -&gt; Moderate\nfilter_vep \\\n-i chr6ch17_mutect2_annotated_with_clinVar_and_plugins.txt \\\n-o moderate_filtered.txt \\\n--force_overwrite \\\n--filter \"(IMPACT is HIGH or IMPACT is MODERATE) and \\\n         (REVEL &gt;= 0.5 or \\\n          am_class = 'likely_pathogenic' or \\\n          SIFT = 'deleterious' or \\\n          PolyPhen = 'probably_damaging')\"\nA glimpse on the results\n\n\nVariant Details\nchr6_10801908_C/G   chr6:10801908   G   ENSG00000111837 ENST00000313243 Transcript  missense_variant    1198    815 272 R/P cGa/cCa COSV57568710    IMPACT=MODERATE;STRAND=-1;VARIANT_CLASS=SNV;SYMBOL=MAK;SYMBOL_SOURCE=HGNC;HGNC_ID=HGNC:6816;BIOTYPE=protein_coding;TSL=5;APPRIS=A1;CCDS=CCDS4516.1;ENSP=ENSP00000313021;SWISSPROT=P20794.202;TREMBL=A0A140VK28.35;UNIPARC=UPI0000001BCD;UNIPROT_ISOFORM=P20794-1;GENE_PHENO=1;SIFT=deleterious(0);PolyPhen=probably_damaging(1);EXON=8/14;DOMAINS=Gene3D:1.10.510.10,AFDB-ENSP_mappings:AF-P20794-F1,Pfam:PF00069,PROSITE_profiles:PS50011,PANTHER:PTHR24055,SMART:SM00220,Superfamily:SSF56112,CDD:cd07830;HGVSc=ENST00000313243.6:c.815G&gt;C;HGVSp=ENSP00000313021.2:p.Arg272Pro;SOMATIC=1;PHENO=1;REVEL=0.884;am_class=likely_pathogenic;am_pathogenicity=0.9946\nchr6_10801908_C/G   chr6:10801908   G   ENSG00000111837 ENST00000354489 Transcript  missense_variant    1081    815 272 R/P cGa/cCa COSV57568710    IMPACT=MODERATE;STRAND=-1;VARIANT_CLASS=SNV;SYMBOL=MAK;SYMBOL_SOURCE=HGNC;HGNC_ID=HGNC:6816;BIOTYPE=protein_coding;CANONICAL=YES;MANE=MANE_Select;MANE_SELECT=NM_001242957.3;TSL=5;APPRIS=P4;CCDS=CCDS75399.1;ENSP=ENSP00000346484;SWISSPROT=P20794.202;UNIPARC=UPI000217CBBA;UNIPROT_ISOFORM=P20794-2;GENE_PHENO=1;SIFT=deleterious(0);PolyPhen=probably_damaging(0.999);EXON=8/15;DOMAINS=Gene3D:1.10.510.10,AFDB-ENSP_mappings:AF-P20794-F1,Pfam:PF00069,PROSITE_profiles:PS50011,PANTHER:PTHR24055,SMART:SM00220,Superfamily:SSF56112,CDD:cd07830;HGVSc=ENST00000354489.7:c.815G&gt;C;HGVSp=ENSP00000346484.3:p.Arg272Pro;SOMATIC=1;PHENO=1;REVEL=0.884;am_class=likely_pathogenic;am_pathogenicity=0.9946\n\n\n\nCategory\nInformation\nDescription\n\n\n\n\nBasic Information\n\n\n\n\nGenomic Location\nchr6:10801908\nGRCh38 coordinates\n\n\nVariant Type\nSNV (C&gt;G)\nSingle nucleotide variant\n\n\nGene\nMAK\nMale Germ Cell-Associated Kinase\n\n\nImpact\nMODERATE\nVEP impact classification\n\n\n\n\n\nTranscript Effects\n\nTranscript 1 (ENST00000313243)\n\n\n\n\n\n\n\n\nFeature\nValue\nNote\n\n\n\n\nConsequence\nmissense_variant\nChanges amino acid\n\n\nProtein Change\np.Arg272Pro\nArginine to Proline\n\n\nTranscript Support\nTSL=5, APPRIS=A1\nLow transcript support level\n\n\nSIFT\ndeleterious(0)\nMaximum deleteriousness score\n\n\nPolyPhen\nprobably_damaging(1)\nMaximum damaging score\n\n\nAffected Domain\nPF00069 (Protein kinase domain)\nFunctional domain impact\n\n\n\n\n\nTranscript 2 (ENST00000354489)\n\n\n\n\n\n\n\n\nFeature\nValue\nNote\n\n\n\n\nConsequence\nmissense_variant\nChanges amino acid\n\n\nProtein Change\np.Arg272Pro\nArginine to Proline\n\n\nTranscript Status\nCANONICAL, MANE_Select\nPrincipal transcript\n\n\nSIFT\ndeleterious(0)\nMaximum deleteriousness score\n\n\nPolyPhen\nprobably_damaging(0.999)\nNear maximum damaging score\n\n\nAffected Domain\nPF00069 (Protein kinase domain)\nFunctional domain impact\n\n\n\n\n\n\nPrediction Tools\n\nREVEL score: 0.884 (&gt;0.5 considered possibly pathogenic)\nAlphaMissense:\n\nClass: likely_pathogenic\nPathogenicity score: 0.9946 (very high confidence)\n\nSpliceRegion: No splice site effects detected\nClinVar: No clinical data found in ClinVar database\nSIF: SIFT=deleterious(0)\nPolyPhen: PolyPhe=probably_damaging(1)\nIMPACT: MODERATE\n\n\n\nAdditional Annotations\n\n\n\nFeature\nValue\nDescription\n\n\n\n\nCOSMIC ID\nCOSV57568710\nCatalogued in COSMIC database\n\n\nSomatic Status\nSOMATIC=1\nConfirmed somatic variant\n\n\nPhenotype\nPHENO=1\nAssociated with phenotype\n\n\nUniProt\nP20794.202\nProtein database reference\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nAt this point we obtained a good annotated set of somatic variants. This paves the way for further analysis. For example you can add more databases to your annotation call, such as COSMIC, cancerhotspots, onkoKB etc. You can also try other plugins, depending on your biological question(s). Those can add addtional data ond possibly additional filtering options.\n\nAdd other databases\nTry additional plugins\nFind interesting genes that could be drivers in your samples\nConsider population frequency of the mutation(s) (common variants are less likely to be pathogenic)\nConsider possible drug-gene interactions\nCheck in the literature\nVisualize the results"
  },
  {
    "objectID": "variant_annotation.html#variant-details",
    "href": "variant_annotation.html#variant-details",
    "title": "Variant annotation",
    "section": "Variant Details",
    "text": "Variant Details\nchr6_10801908_C/G   chr6:10801908   G   ENSG00000111837 ENST00000313243 Transcript  missense_variant    1198    815 272 R/P cGa/cCa COSV57568710    IMPACT=MODERATE;STRAND=-1;VARIANT_CLASS=SNV;SYMBOL=MAK;SYMBOL_SOURCE=HGNC;HGNC_ID=HGNC:6816;BIOTYPE=protein_coding;TSL=5;APPRIS=A1;CCDS=CCDS4516.1;ENSP=ENSP00000313021;SWISSPROT=P20794.202;TREMBL=A0A140VK28.35;UNIPARC=UPI0000001BCD;UNIPROT_ISOFORM=P20794-1;GENE_PHENO=1;SIFT=deleterious(0);PolyPhen=probably_damaging(1);EXON=8/14;DOMAINS=Gene3D:1.10.510.10,AFDB-ENSP_mappings:AF-P20794-F1,Pfam:PF00069,PROSITE_profiles:PS50011,PANTHER:PTHR24055,SMART:SM00220,Superfamily:SSF56112,CDD:cd07830;HGVSc=ENST00000313243.6:c.815G&gt;C;HGVSp=ENSP00000313021.2:p.Arg272Pro;SOMATIC=1;PHENO=1;REVEL=0.884;am_class=likely_pathogenic;am_pathogenicity=0.9946\nchr6_10801908_C/G   chr6:10801908   G   ENSG00000111837 ENST00000354489 Transcript  missense_variant    1081    815 272 R/P cGa/cCa COSV57568710    IMPACT=MODERATE;STRAND=-1;VARIANT_CLASS=SNV;SYMBOL=MAK;SYMBOL_SOURCE=HGNC;HGNC_ID=HGNC:6816;BIOTYPE=protein_coding;CANONICAL=YES;MANE=MANE_Select;MANE_SELECT=NM_001242957.3;TSL=5;APPRIS=P4;CCDS=CCDS75399.1;ENSP=ENSP00000346484;SWISSPROT=P20794.202;UNIPARC=UPI000217CBBA;UNIPROT_ISOFORM=P20794-2;GENE_PHENO=1;SIFT=deleterious(0);PolyPhen=probably_damaging(0.999);EXON=8/15;DOMAINS=Gene3D:1.10.510.10,AFDB-ENSP_mappings:AF-P20794-F1,Pfam:PF00069,PROSITE_profiles:PS50011,PANTHER:PTHR24055,SMART:SM00220,Superfamily:SSF56112,CDD:cd07830;HGVSc=ENST00000354489.7:c.815G&gt;C;HGVSp=ENSP00000346484.3:p.Arg272Pro;SOMATIC=1;PHENO=1;REVEL=0.884;am_class=likely_pathogenic;am_pathogenicity=0.9946\n\n\n\nCategory\nInformation\nDescription\n\n\n\n\nBasic Information\n\n\n\n\nGenomic Location\nchr6:10801908\nGRCh38 coordinates\n\n\nVariant Type\nSNV (C&gt;G)\nSingle nucleotide variant\n\n\nGene\nMAK\nMale Germ Cell-Associated Kinase\n\n\nImpact\nMODERATE\nVEP impact classification"
  },
  {
    "objectID": "variant_annotation.html#transcript-effects",
    "href": "variant_annotation.html#transcript-effects",
    "title": "Variant annotation",
    "section": "Transcript Effects",
    "text": "Transcript Effects\n\nTranscript 1 (ENST00000313243)\n\n\n\n\n\n\n\n\nFeature\nValue\nNote\n\n\n\n\nConsequence\nmissense_variant\nChanges amino acid\n\n\nProtein Change\np.Arg272Pro\nArginine to Proline\n\n\nTranscript Support\nTSL=5, APPRIS=A1\nLow transcript support level\n\n\nSIFT\ndeleterious(0)\nMaximum deleteriousness score\n\n\nPolyPhen\nprobably_damaging(1)\nMaximum damaging score\n\n\nAffected Domain\nPF00069 (Protein kinase domain)\nFunctional domain impact\n\n\n\n\n\nTranscript 2 (ENST00000354489)\n\n\n\n\n\n\n\n\nFeature\nValue\nNote\n\n\n\n\nConsequence\nmissense_variant\nChanges amino acid\n\n\nProtein Change\np.Arg272Pro\nArginine to Proline\n\n\nTranscript Status\nCANONICAL, MANE_Select\nPrincipal transcript\n\n\nSIFT\ndeleterious(0)\nMaximum deleteriousness score\n\n\nPolyPhen\nprobably_damaging(0.999)\nNear maximum damaging score\n\n\nAffected Domain\nPF00069 (Protein kinase domain)\nFunctional domain impact"
  },
  {
    "objectID": "variant_annotation.html#prediction-tools",
    "href": "variant_annotation.html#prediction-tools",
    "title": "Variant annotation",
    "section": "Prediction Tools",
    "text": "Prediction Tools\n\nREVEL score: 0.884 (&gt;0.5 considered possibly pathogenic)\nAlphaMissense:\n\nClass: likely_pathogenic\nPathogenicity score: 0.9946 (very high confidence)\n\nSpliceRegion: No splice site effects detected\nClinVar: No clinical data found in ClinVar database\nSIF: SIFT=deleterious(0)\nPolyPhen: PolyPhe=probably_damaging(1)\nIMPACT: MODERATE"
  },
  {
    "objectID": "variant_annotation.html#additional-annotations",
    "href": "variant_annotation.html#additional-annotations",
    "title": "Variant annotation",
    "section": "Additional Annotations",
    "text": "Additional Annotations\n\n\n\nFeature\nValue\nDescription\n\n\n\n\nCOSMIC ID\nCOSV57568710\nCatalogued in COSMIC database\n\n\nSomatic Status\nSOMATIC=1\nConfirmed somatic variant\n\n\nPhenotype\nPHENO=1\nAssociated with phenotype\n\n\nUniProt\nP20794.202\nProtein database reference"
  },
  {
    "objectID": "variant_annotation.html#tips-for-cancer-variant-analysis",
    "href": "variant_annotation.html#tips-for-cancer-variant-analysis",
    "title": "Variant annotation",
    "section": "Tips for Cancer Variant Analysis",
    "text": "Tips for Cancer Variant Analysis\n\nQuality Control\n\nFilter low-quality variants before VEP annotation\nUse matched normal samples when available (if not consider PONs)\nConsider sequencing artifacts\n\nAnnotation Strategy\n\nUse multiple prediction algorithms\nConsider tissue-specific expression\nInclude population frequencies\nAdd clinical annotations\n\nInterpretation Guidelines\n\nUse cancer-specific frameworks for somatic variants\nDocument all filtering criteria\nMaintain version control of annotation sources\n\n\n\nDatabases\n\nCOSMIC: https://cancer.sanger.ac.uk/cosmic\nClinVar: https://www.ncbi.nlm.nih.gov/clinvar/\ngnomAD: https://gnomad.broadinstitute.org/\nOncoKB: https://www.oncokb.org/\n\n\n\nDownload data to COSMIC\n\nFor COSMIC: We cannot provide those files (they require licensing), you need to register and download the files. CosmicMutantExport.tsv.gz You can register here:\n\n\n\nTools and Documentation\n\nVEP Documentation: http://www.ensembl.org/info/docs/tools/vep/\nVEP GitHub: https://github.com/Ensembl/ensembl-vep\nCancer Gene Census: https://cancer.sanger.ac.uk/census\n\nRemember to:\n\nAlways verify file paths and permissions\nCheck input data format and quality\nValidate output at each step\nConsider computational resources when processing large datasets\nDocument any modifications to the pipeline"
  },
  {
    "objectID": "variant_annotation.html#references",
    "href": "variant_annotation.html#references",
    "title": "Variant annotation",
    "section": "References",
    "text": "References\n\nMcLaren W, et al. The Ensembl Variant Effect Predictor. Genome Biology (2016)\nEilbeck K, et al. The Sequence Ontology: a tool for the unification of genome annotations. Genome Biology (2005)\nRichards S, et al. Standards and guidelines for the interpretation of sequence variants. Genetics in Medicine (2015)"
  }
]