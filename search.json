[
  {
    "objectID": "variant_calling.html",
    "href": "variant_calling.html",
    "title": "Variant calling",
    "section": "",
    "text": "If you are participating in this course with a teacher, you have received a link and a password. Copy-paste the link (including the port, e.g.: http://12.345.678.91:10002) in your browser. This should result in the following page:\n\n\n\n\n\n\n\nNote\n\n\n\nThe link gives you access to a web version of Visual Studio Code. This is a powerful code editor that you can also use as a local application on your computer.\n\n\nType in the password that was provided to you by the teacher. Now let’s open the terminal. You can do that with ++ctrl+grave++. Or by clicking Application menu &gt; Terminal &gt; New Terminal:\n\nFor a.o. efficiency and reproducibility it makes sense to execute your commands from a script. With use of the ‘new file’ button:\n\n\n\n\nWe will start the exercises with pre-aligned bam files. Create a directory ~/project/results/alignments and download and extract the files in that folder:\nmkdir -p ~/project/results/alignments\ncd ~/project/results/alignments\nwget linkk\ngunzip bam_files.tar.gz\n\n\n\nFirst we use the information in the header to get information about the contents of the bam file and how it was generated.\n\n\n\n\n\n\nExercise\n\n\n\nCheck out the contents of the bam header with samtools view -H, and answer the following questions:\n\nHow is the bam file sorted?\nWhich chromosomes were used as reference?\nHow many read groups are in there, and what is the readgroup ID and what is the sample name?\nWhich aligner was used?\nIf there are duplicates in there, how are they marked?\nWhich other programs were run to create the bam file?\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nTo get information on the bam header we run\nsamtools view -H normal.recal.bam\nWhich returns:\n@HD     VN:1.6  SO:coordinate\n@SQ     SN:chr6 LN:170805979\n@SQ     SN:chr17        LN:83257441\n@RG     ID:HWI-ST466.C1TD1ACXX.normal   LB:normal       PL:ILLUMINA     SM:normal       PU:HWI-ST466.C1TD1ACXX\n@PG     ID:bwa  PN:bwa  VN:0.7.17-r1188 CL:bwa mem /config/data/reference//ref_genome.fa /config/data/reads/normal_R1.fastq.gz /config/data/reads/normal_R2.fastq.gz\n@PG     ID:samtools     PN:samtools     PP:bwa  VN:1.21 CL:samtools sort\n@PG     ID:samtools.1   PN:samtools     PP:samtools     VN:1.21 CL:samtools view -bh\n@PG     ID:MarkDuplicates       VN:Version:4.5.0.0      CL:MarkDuplicates --INPUT /config/data/alignments/normal.rg.bam --OUTPUT /config/data/alignments/normal.rg.md.bam --METRICS_FILE /config/data/alignments/marked_dup_metrics_normal.txt ...   PN:MarkDuplicates\n@PG     ID:GATK ApplyBQSR       VN:4.5.0.0      CL:ApplyBQSR --output /config/project/data/alignments/.recal.bam --bqsr-recal-file /config/project/data/alignments/normal.bqsr.recal.table --input /config/project/data/alignments/normal.rg.md.bam ...        PN:GATK ApplyBQSR\n@PG     ID:samtools.2   PN:samtools     PP:samtools.1   VN:1.21 CL:samtools view -H tumor.recal.bam\n\nFrom the @HD tag, we can see that the bam file is sorted by coordinate.\nWe have two lines starting with @SQ, which gives us information about the reference used. The reference genome used contains chromosomes 6 and 17.\nWe have one line starting with @RG. Specifying there is a read group with ID HWI-ST466.C1TD1ACXX.normal and sample name normal.\nIn order to know which programs were run to generate this bam file, we can use the @PG tags. Here, we see that the aligner used was bwa mem\nThe duplicates were marked with MarkDuplicates.\nTo sort and compress samtools sort and samtools view were used. For base quality score recalibration (BQSR) GATK ApplyBQSR was used.\n\n\n\n\nNow we extract information from the alignments themselves. We first have a look at few alignments and then get a summary of the alignments with samtools flagstat.\n\n\n\n\n\n\nExercise\n\n\n\nCheck out the first few alignments with samtools view and head.\n\nWhat is likely the read length used?\nAre the reads single-end or paired-end?\nAre the first reads tagged with the readgroup ID?\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe command:\nsamtools view normal.recal.bam | head -3\nReturns the first three alignments:\nHWI-ST466:135068617:C1TD1ACXX:7:1114:9733:82689 163     chr6    60001   60      100M    =       60106   205     GATCTTATATAACTGTGAGATTAATCTCAGATAATGACACAAAATATAGTGAAGTTGGTAAGTTATTTAGTAAAGCTCATGAAAATTGTGCCCTCCATTC     ;B@EDB@A@A@DDDGBGBFCBC?DBEEGCGCAADAGCECDCDDDBABAGBECEGCBHH@?EGBCBCDDBHBAEEHGDFBBHBDDDBCHBGEFFEGEDBBG     MC:Z:100M       MD:Z:100        PG:Z:MarkDuplicates     RG:Z:HWI-ST466.C1TD1ACXX.normal NM:i:0  AS:i:100        XS:i:0\nHWI-ST466:135068617:C1TD1ACXX:7:1303:2021:90688 99      chr6    60001   60      100M    =       60104   203     GATCTTATATAACTGTGAGATTAATCTCAGATAATGACACAAAATATAGTGAAGTTGGTAAGTTATTTAGTAAAGCTCATGAAAATTGTGCCCTCCATTC     &gt;A@FDB@A?@&gt;DDCE@FAF@?BAC&gt;ECFCGBAADBEADBDCDDD@@A@FAFADD?ABF@@EF?@ABCDAFB?DCGEBEB@EBCDCBCHBFEFFDGFCBBG     MC:Z:100M       MD:Z:100        PG:Z:MarkDuplicates     RG:Z:HWI-ST466.C1TD1ACXX.normal NM:i:0  AS:i:100        XS:i:0\nHWI-ST466:135068617:C1TD1ACXX:7:2304:7514:30978 113     chr6    60001   60      2S98M   =       61252   1194    TAGATCTTATATAACTGTGAGATTAATCTCAGATAATGACACAAAATATAGTGAAGTTGGTAAGTTATTTAGTAAAGCTCATGAAAATTGTGCCCTCCAT     &gt;DHABFEACBBBCBGCECHEGBEACBDHCGCHCBDBBFAEAGBCCB@BAEECGBEEDBED&gt;@EDDABDDADE@CBDFFBFBCFCCBADBDBDFFFAFF?@     MC:Z:60S40M     MD:Z:98 PG:Z:MarkDuplicates     RG:Z:HWI-ST466.C1TD1ACXX.normal NM:i:0  AS:i:98 XS:i:0\n\nAt the CIGAR strings we see 100M and 2S98M, meaning that the original read had 100 base pairs. So it’s likely a read length of 100 bp has been used.\nThis question might be a bit more challenging. In the 5th column we see an equal sign (=). This shows that the mate is mapped to same chromsome, so suggesting we are working with paired-end reads. Secondly, at the @PG header tag, we saw that bwa mem took two fastq files (normal_R1.fastq.gz and normal_R2.fastq.gz) as input. Lastly, we can use the sam flags in the second column to figure that out. If you paste the first flag, 163, in the explain sam flags website, we can see that the read is paired.\nYes, the read group tag starts with RG, and is specified for all three alignments.\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nUse samtools flagstat to summarize the alignments in both bam files. How many reads are in the bam files? And how many alignment are marked as duplicate?\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nsamtools flagstat normal.recal.bam\nreturns:\n12744793 + 0 in total (QC-passed reads + QC-failed reads)\n12733034 + 0 primary\n0 + 0 secondary\n11759 + 0 supplementary\n1397598 + 0 duplicates\n1397598 + 0 primary duplicates\n12671529 + 0 mapped (99.43% : N/A)\n12659770 + 0 primary mapped (99.42% : N/A)\n12733034 + 0 paired in sequencing\n6366517 + 0 read1\n6366517 + 0 read2\n12515974 + 0 properly paired (98.30% : N/A)\n12586532 + 0 with itself and mate mapped\n73238 + 0 singletons (0.58% : N/A)\n20414 + 0 with mate mapped to a different chr\n13194 + 0 with mate mapped to a different chr (mapQ&gt;=5)\nShowing us that we have 12,744,793 reads and 1,397,598 alignments were marked as duplicate. If we do the same for the tumor bam file we see that it has 16,674,562 reads and 1,871,521 alignment marked as duplicate.\n\n\n\nSo, all looks good until now. We have many reads, high alignment rates, and the bam files seem to be ready for variant analysis, because they have read groups, duplicates are marked and they are sorted by coordinate. However, since we are working with whole exome sequencing (WES) data, we would like to know whether the reads align to the target regions and what kind of coverage we have. For this, we use gatk CollectHsMetrics.\n\n\n\n\n\n\nExercise\n\n\n\nCreate a script called 02_gatk_collecthsmetrics.sh in ~/project/scripts to run gatk CollectHsMetrics on the two bam files. Here’s an example:\nALIGNDIR=~/project/results/alignments\nREFDIR=~/project/data/reference\nRESOURCEDIR=~/project/data/resources\n\nfor sample in tumor normal\ndo\n    gatk CollectHsMetrics \\\n    -I \"$ALIGNDIR\"/\"$sample\".recal.bam \\\n    -O \"$ALIGNDIR\"/\"$sample\".recal.bam_hs_metrics.txt \\\n    -R \"$REFDIR\"/ref_genome.fa \\\n    --BAIT_INTERVALS \"$REFDIR\"/exome_regions.bed.interval_list \\\n    --TARGET_INTERVALS \"$REFDIR\"/exome_regions.bed.interval_list\ndone \nThe produced reports are not so easy to read. To parse the metrics file, we run multiqc on the directory:\ncd ~/project/results/alignments\nmultiqc .\nDownload the multiqc report (multiqc_report.html) by right-clicking on the file and select ‘Download’. Check out the hybrid-selection metrics. How did the hybrid capture go? Are most bases on-target? What kind of coverages can we expect in the target regions?\n\n\n\n\n\n\n\n\nNote\n\n\n\nYou can find the documentation on the different metrics here. Note that the descriptions are not always correct. The metrics with ON_BAIT contain information including duplicates, while ON_TARGET without duplicates. This has been an issue since 2020, and hasn’t been worked on unfortunately.\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWe see that we have a fold enrichment of around 22 and about 45% usable bases on-target. About 90% were ‘selected bases’, which means bases aligning within 250 bp of the target region. We’re looking at a de-duplicated coverage of 84x for the normal sample and 114.3x for the tumor sample. So, on average, we seem to have acceptable coverages for both samples.\n\n\n\nNow that we have quality-controlled the BAM files, we can go ahead with the variant calling itself. For this, we used mutect2 which is a somatic variant caller from GATK based on HaplotypeCaller. In addition to the expected bam files and references genome, the mutect2 command requires some additional input:\n\n--intervals: the intervals of our target regions. This is in the interval_list format.\n-normal: the sample name of the normal sample. So, the SM tag of the read group of the normal sample.\n--germline-resource: know sites of germline variants with their allele frequencies in the population. These are used to estimate the confidence of a germline variant in the normal sample.\n--panel-of-normals: A VCF generated from normal samples that contain sites with known technical artifacts. Ideally, you create a PON from your own normal samples, but this is typically recommended if you have more than 40 normal samples. Therefore, here, we use a pre-generated PON from the 1000 genomes project. More information on PON in this article.\n\n\n\n\n\n\n\nExercise\n\n\n\nCheck out the manual of Mutect2 and replace the placeholders FIXME with the required values of the Mutect2 below command and run it:\n\n#!/usr/bin/env bash\n\nALIGNDIR=~/project/data/alignments\nREFDIR=~/project/data/reference\nRESOURCEDIR=~/project/data/resources\nVARIANTDIR=~/project/data/variants\n\nmkdir -p $VARIANTDIR\n\ngatk Mutect2 \\\n-R FIXME \\\n--intervals \"$REFDIR\"/exome_regions.bed.interval_list \\\n-I FIXME \\\n-I FIXME \\\n-normal FIXME \\\n--germline-resource \"$RESOURCEDIR\"/af-only-gnomad.hg38.subset.vcf.gz \\\n--panel-of-normals \"$RESOURCEDIR\"/1000g_pon.hg38.subset.vcf.gz \\\n-O \"$VARIANTDIR\"/somatic.vcf.gz\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n#!/usr/bin/env bash\n\nALIGNDIR=~/project/data/alignments\nREFDIR=~/project/data/reference\nRESOURCEDIR=~/project/data/resources\nVARIANTDIR=~/project/data/variants\n\nmkdir -p $VARIANTDIR\n\ngatk Mutect2 \\\n-R \"$REFDIR\"/ref_genome.fa \\\n--intervals \"$REFDIR\"/exome_regions.bed.interval_list \\\n-I \"$ALIGNDIR\"/sample.recal.bam \\\n-I \"$ALIGNDIR\"/normal.recal.bam \\\n-normal normal \\\n--germline-resource \"$RESOURCEDIR\"/af-only-gnomad.hg38.subset.vcf.gz \\\n--panel-of-normals \"$RESOURCEDIR\"/1000g_pon.hg38.subset.vcf.gz \\\n-O \"$VARIANTDIR\"/somatic.vcf.gz"
  },
  {
    "objectID": "variant_calling.html#exercises",
    "href": "variant_calling.html#exercises",
    "title": "Variant calling",
    "section": "",
    "text": "If you are participating in this course with a teacher, you have received a link and a password. Copy-paste the link (including the port, e.g.: http://12.345.678.91:10002) in your browser. This should result in the following page:\n\n\n\n\n\n\n\nNote\n\n\n\nThe link gives you access to a web version of Visual Studio Code. This is a powerful code editor that you can also use as a local application on your computer.\n\n\nType in the password that was provided to you by the teacher. Now let’s open the terminal. You can do that with ++ctrl+grave++. Or by clicking Application menu &gt; Terminal &gt; New Terminal:\n\nFor a.o. efficiency and reproducibility it makes sense to execute your commands from a script. With use of the ‘new file’ button:\n\n\n\n\nWe will start the exercises with pre-aligned bam files. Create a directory ~/project/results/alignments and download and extract the files in that folder:\nmkdir -p ~/project/results/alignments\ncd ~/project/results/alignments\nwget linkk\ngunzip bam_files.tar.gz\n\n\n\nFirst we use the information in the header to get information about the contents of the bam file and how it was generated.\n\n\n\n\n\n\nExercise\n\n\n\nCheck out the contents of the bam header with samtools view -H, and answer the following questions:\n\nHow is the bam file sorted?\nWhich chromosomes were used as reference?\nHow many read groups are in there, and what is the readgroup ID and what is the sample name?\nWhich aligner was used?\nIf there are duplicates in there, how are they marked?\nWhich other programs were run to create the bam file?\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nTo get information on the bam header we run\nsamtools view -H normal.recal.bam\nWhich returns:\n@HD     VN:1.6  SO:coordinate\n@SQ     SN:chr6 LN:170805979\n@SQ     SN:chr17        LN:83257441\n@RG     ID:HWI-ST466.C1TD1ACXX.normal   LB:normal       PL:ILLUMINA     SM:normal       PU:HWI-ST466.C1TD1ACXX\n@PG     ID:bwa  PN:bwa  VN:0.7.17-r1188 CL:bwa mem /config/data/reference//ref_genome.fa /config/data/reads/normal_R1.fastq.gz /config/data/reads/normal_R2.fastq.gz\n@PG     ID:samtools     PN:samtools     PP:bwa  VN:1.21 CL:samtools sort\n@PG     ID:samtools.1   PN:samtools     PP:samtools     VN:1.21 CL:samtools view -bh\n@PG     ID:MarkDuplicates       VN:Version:4.5.0.0      CL:MarkDuplicates --INPUT /config/data/alignments/normal.rg.bam --OUTPUT /config/data/alignments/normal.rg.md.bam --METRICS_FILE /config/data/alignments/marked_dup_metrics_normal.txt ...   PN:MarkDuplicates\n@PG     ID:GATK ApplyBQSR       VN:4.5.0.0      CL:ApplyBQSR --output /config/project/data/alignments/.recal.bam --bqsr-recal-file /config/project/data/alignments/normal.bqsr.recal.table --input /config/project/data/alignments/normal.rg.md.bam ...        PN:GATK ApplyBQSR\n@PG     ID:samtools.2   PN:samtools     PP:samtools.1   VN:1.21 CL:samtools view -H tumor.recal.bam\n\nFrom the @HD tag, we can see that the bam file is sorted by coordinate.\nWe have two lines starting with @SQ, which gives us information about the reference used. The reference genome used contains chromosomes 6 and 17.\nWe have one line starting with @RG. Specifying there is a read group with ID HWI-ST466.C1TD1ACXX.normal and sample name normal.\nIn order to know which programs were run to generate this bam file, we can use the @PG tags. Here, we see that the aligner used was bwa mem\nThe duplicates were marked with MarkDuplicates.\nTo sort and compress samtools sort and samtools view were used. For base quality score recalibration (BQSR) GATK ApplyBQSR was used.\n\n\n\n\nNow we extract information from the alignments themselves. We first have a look at few alignments and then get a summary of the alignments with samtools flagstat.\n\n\n\n\n\n\nExercise\n\n\n\nCheck out the first few alignments with samtools view and head.\n\nWhat is likely the read length used?\nAre the reads single-end or paired-end?\nAre the first reads tagged with the readgroup ID?\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe command:\nsamtools view normal.recal.bam | head -3\nReturns the first three alignments:\nHWI-ST466:135068617:C1TD1ACXX:7:1114:9733:82689 163     chr6    60001   60      100M    =       60106   205     GATCTTATATAACTGTGAGATTAATCTCAGATAATGACACAAAATATAGTGAAGTTGGTAAGTTATTTAGTAAAGCTCATGAAAATTGTGCCCTCCATTC     ;B@EDB@A@A@DDDGBGBFCBC?DBEEGCGCAADAGCECDCDDDBABAGBECEGCBHH@?EGBCBCDDBHBAEEHGDFBBHBDDDBCHBGEFFEGEDBBG     MC:Z:100M       MD:Z:100        PG:Z:MarkDuplicates     RG:Z:HWI-ST466.C1TD1ACXX.normal NM:i:0  AS:i:100        XS:i:0\nHWI-ST466:135068617:C1TD1ACXX:7:1303:2021:90688 99      chr6    60001   60      100M    =       60104   203     GATCTTATATAACTGTGAGATTAATCTCAGATAATGACACAAAATATAGTGAAGTTGGTAAGTTATTTAGTAAAGCTCATGAAAATTGTGCCCTCCATTC     &gt;A@FDB@A?@&gt;DDCE@FAF@?BAC&gt;ECFCGBAADBEADBDCDDD@@A@FAFADD?ABF@@EF?@ABCDAFB?DCGEBEB@EBCDCBCHBFEFFDGFCBBG     MC:Z:100M       MD:Z:100        PG:Z:MarkDuplicates     RG:Z:HWI-ST466.C1TD1ACXX.normal NM:i:0  AS:i:100        XS:i:0\nHWI-ST466:135068617:C1TD1ACXX:7:2304:7514:30978 113     chr6    60001   60      2S98M   =       61252   1194    TAGATCTTATATAACTGTGAGATTAATCTCAGATAATGACACAAAATATAGTGAAGTTGGTAAGTTATTTAGTAAAGCTCATGAAAATTGTGCCCTCCAT     &gt;DHABFEACBBBCBGCECHEGBEACBDHCGCHCBDBBFAEAGBCCB@BAEECGBEEDBED&gt;@EDDABDDADE@CBDFFBFBCFCCBADBDBDFFFAFF?@     MC:Z:60S40M     MD:Z:98 PG:Z:MarkDuplicates     RG:Z:HWI-ST466.C1TD1ACXX.normal NM:i:0  AS:i:98 XS:i:0\n\nAt the CIGAR strings we see 100M and 2S98M, meaning that the original read had 100 base pairs. So it’s likely a read length of 100 bp has been used.\nThis question might be a bit more challenging. In the 5th column we see an equal sign (=). This shows that the mate is mapped to same chromsome, so suggesting we are working with paired-end reads. Secondly, at the @PG header tag, we saw that bwa mem took two fastq files (normal_R1.fastq.gz and normal_R2.fastq.gz) as input. Lastly, we can use the sam flags in the second column to figure that out. If you paste the first flag, 163, in the explain sam flags website, we can see that the read is paired.\nYes, the read group tag starts with RG, and is specified for all three alignments.\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nUse samtools flagstat to summarize the alignments in both bam files. How many reads are in the bam files? And how many alignment are marked as duplicate?\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nsamtools flagstat normal.recal.bam\nreturns:\n12744793 + 0 in total (QC-passed reads + QC-failed reads)\n12733034 + 0 primary\n0 + 0 secondary\n11759 + 0 supplementary\n1397598 + 0 duplicates\n1397598 + 0 primary duplicates\n12671529 + 0 mapped (99.43% : N/A)\n12659770 + 0 primary mapped (99.42% : N/A)\n12733034 + 0 paired in sequencing\n6366517 + 0 read1\n6366517 + 0 read2\n12515974 + 0 properly paired (98.30% : N/A)\n12586532 + 0 with itself and mate mapped\n73238 + 0 singletons (0.58% : N/A)\n20414 + 0 with mate mapped to a different chr\n13194 + 0 with mate mapped to a different chr (mapQ&gt;=5)\nShowing us that we have 12,744,793 reads and 1,397,598 alignments were marked as duplicate. If we do the same for the tumor bam file we see that it has 16,674,562 reads and 1,871,521 alignment marked as duplicate.\n\n\n\nSo, all looks good until now. We have many reads, high alignment rates, and the bam files seem to be ready for variant analysis, because they have read groups, duplicates are marked and they are sorted by coordinate. However, since we are working with whole exome sequencing (WES) data, we would like to know whether the reads align to the target regions and what kind of coverage we have. For this, we use gatk CollectHsMetrics.\n\n\n\n\n\n\nExercise\n\n\n\nCreate a script called 02_gatk_collecthsmetrics.sh in ~/project/scripts to run gatk CollectHsMetrics on the two bam files. Here’s an example:\nALIGNDIR=~/project/results/alignments\nREFDIR=~/project/data/reference\nRESOURCEDIR=~/project/data/resources\n\nfor sample in tumor normal\ndo\n    gatk CollectHsMetrics \\\n    -I \"$ALIGNDIR\"/\"$sample\".recal.bam \\\n    -O \"$ALIGNDIR\"/\"$sample\".recal.bam_hs_metrics.txt \\\n    -R \"$REFDIR\"/ref_genome.fa \\\n    --BAIT_INTERVALS \"$REFDIR\"/exome_regions.bed.interval_list \\\n    --TARGET_INTERVALS \"$REFDIR\"/exome_regions.bed.interval_list\ndone \nThe produced reports are not so easy to read. To parse the metrics file, we run multiqc on the directory:\ncd ~/project/results/alignments\nmultiqc .\nDownload the multiqc report (multiqc_report.html) by right-clicking on the file and select ‘Download’. Check out the hybrid-selection metrics. How did the hybrid capture go? Are most bases on-target? What kind of coverages can we expect in the target regions?\n\n\n\n\n\n\n\n\nNote\n\n\n\nYou can find the documentation on the different metrics here. Note that the descriptions are not always correct. The metrics with ON_BAIT contain information including duplicates, while ON_TARGET without duplicates. This has been an issue since 2020, and hasn’t been worked on unfortunately.\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWe see that we have a fold enrichment of around 22 and about 45% usable bases on-target. About 90% were ‘selected bases’, which means bases aligning within 250 bp of the target region. We’re looking at a de-duplicated coverage of 84x for the normal sample and 114.3x for the tumor sample. So, on average, we seem to have acceptable coverages for both samples.\n\n\n\nNow that we have quality-controlled the BAM files, we can go ahead with the variant calling itself. For this, we used mutect2 which is a somatic variant caller from GATK based on HaplotypeCaller. In addition to the expected bam files and references genome, the mutect2 command requires some additional input:\n\n--intervals: the intervals of our target regions. This is in the interval_list format.\n-normal: the sample name of the normal sample. So, the SM tag of the read group of the normal sample.\n--germline-resource: know sites of germline variants with their allele frequencies in the population. These are used to estimate the confidence of a germline variant in the normal sample.\n--panel-of-normals: A VCF generated from normal samples that contain sites with known technical artifacts. Ideally, you create a PON from your own normal samples, but this is typically recommended if you have more than 40 normal samples. Therefore, here, we use a pre-generated PON from the 1000 genomes project. More information on PON in this article.\n\n\n\n\n\n\n\nExercise\n\n\n\nCheck out the manual of Mutect2 and replace the placeholders FIXME with the required values of the Mutect2 below command and run it:\n\n#!/usr/bin/env bash\n\nALIGNDIR=~/project/data/alignments\nREFDIR=~/project/data/reference\nRESOURCEDIR=~/project/data/resources\nVARIANTDIR=~/project/data/variants\n\nmkdir -p $VARIANTDIR\n\ngatk Mutect2 \\\n-R FIXME \\\n--intervals \"$REFDIR\"/exome_regions.bed.interval_list \\\n-I FIXME \\\n-I FIXME \\\n-normal FIXME \\\n--germline-resource \"$RESOURCEDIR\"/af-only-gnomad.hg38.subset.vcf.gz \\\n--panel-of-normals \"$RESOURCEDIR\"/1000g_pon.hg38.subset.vcf.gz \\\n-O \"$VARIANTDIR\"/somatic.vcf.gz\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n#!/usr/bin/env bash\n\nALIGNDIR=~/project/data/alignments\nREFDIR=~/project/data/reference\nRESOURCEDIR=~/project/data/resources\nVARIANTDIR=~/project/data/variants\n\nmkdir -p $VARIANTDIR\n\ngatk Mutect2 \\\n-R \"$REFDIR\"/ref_genome.fa \\\n--intervals \"$REFDIR\"/exome_regions.bed.interval_list \\\n-I \"$ALIGNDIR\"/sample.recal.bam \\\n-I \"$ALIGNDIR\"/normal.recal.bam \\\n-normal normal \\\n--germline-resource \"$RESOURCEDIR\"/af-only-gnomad.hg38.subset.vcf.gz \\\n--panel-of-normals \"$RESOURCEDIR\"/1000g_pon.hg38.subset.vcf.gz \\\n-O \"$VARIANTDIR\"/somatic.vcf.gz"
  },
  {
    "objectID": "precourse_preparations.html",
    "href": "precourse_preparations.html",
    "title": "Precourse preparations",
    "section": "",
    "text": "Participants should have knowledge in NGS techniques, quality control and alignment to a reference genome, and detection of genomic variants from read alignment to variant calling and annotation.\nThe competences and knowledge levels required correspond to those taught in courses such as: NGS - Quality Control, Alignment, Visualisation and NGS-Genome Variant Analysis.\nParticipants should have a basic understanding of working with command line tools on Unix-based systems. You can test your skills with Unix with the quiz here. If you do not feel comfortable with UNIX commands, please take our Unix fundamentals e-learning module.\n\n\n\nParticipants should have their own computer with a browser installed (e.g. chrome, firefox, edge), and can access http websites. Test it here: http://httpforever.com/."
  },
  {
    "objectID": "precourse_preparations.html#prerequisites",
    "href": "precourse_preparations.html#prerequisites",
    "title": "Precourse preparations",
    "section": "",
    "text": "Participants should have knowledge in NGS techniques, quality control and alignment to a reference genome, and detection of genomic variants from read alignment to variant calling and annotation.\nThe competences and knowledge levels required correspond to those taught in courses such as: NGS - Quality Control, Alignment, Visualisation and NGS-Genome Variant Analysis.\nParticipants should have a basic understanding of working with command line tools on Unix-based systems. You can test your skills with Unix with the quiz here. If you do not feel comfortable with UNIX commands, please take our Unix fundamentals e-learning module.\n\n\n\nParticipants should have their own computer with a browser installed (e.g. chrome, firefox, edge), and can access http websites. Test it here: http://httpforever.com/."
  },
  {
    "objectID": "course_schedule.html",
    "href": "course_schedule.html",
    "title": "Course schedule",
    "section": "",
    "text": "Note\n\n\n\nApart from the starting time the time schedule is indicative. Because we can not plan a course by the minute, in practice the time points will deviate."
  },
  {
    "objectID": "course_schedule.html#day-1",
    "href": "course_schedule.html#day-1",
    "title": "Course schedule",
    "section": "Day 1",
    "text": "Day 1\n\n\n\nblock\nstart\nend\nsubject\n\n\n\n\nintroduction\n9:00 AM\n9:30 AM\nIntroduction\n\n\nblock 1\n9:30 AM\n10:30 AM\nVariant calling - lecture\n\n\n\n10:30 AM\n11:00 AM\nBREAK\n\n\nblock 2\n11:00 AM\n12:00 PM\nVariant calling - exercises\n\n\n\n12:00 PM\n1:00 PM\nBREAK\n\n\nblock 3\n1:00 PM\n1:45 PM\nVariant annotation - lecture\n\n\nblock 4\n1:45 PM\n3:00\nVariant annotation - exercises\n\n\n\n3:00 PM\n3:30 PM\nBREAK\n\n\nblock 4\n3:30 PM\n4:10 PM\nVariant annotation - exercises\n\n\nblock 5\n4:10 PM\n5:00 PM\nVisualization - exercises"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "SIB course cancer variant analysis",
    "section": "",
    "text": "Flavio Lombardo ORCiD\nGeert van Geest ORCiD"
  },
  {
    "objectID": "index.html#teachers-and-authors",
    "href": "index.html#teachers-and-authors",
    "title": "SIB course cancer variant analysis",
    "section": "",
    "text": "Flavio Lombardo ORCiD\nGeert van Geest ORCiD"
  },
  {
    "objectID": "index.html#attribution",
    "href": "index.html#attribution",
    "title": "SIB course cancer variant analysis",
    "section": "Attribution",
    "text": "Attribution\nParts of this course are inspired by the Precision medicine course, from the Griffith lab."
  },
  {
    "objectID": "index.html#license-copyright",
    "href": "index.html#license-copyright",
    "title": "SIB course cancer variant analysis",
    "section": "License & copyright",
    "text": "License & copyright\nLicense: CC BY 4.0\nCopyright: SIB Swiss Institute of Bioinformatics"
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "SIB course cancer variant analysis",
    "section": "Overview",
    "text": "Overview\nCancer is a disease of the genome. Mutations of genes that regulate cell proliferation and cell death result in uncontrolled growth eventually causing symptoms. During cancer progression, mutations build up that not only affect cell growth, but also can suppress the immune system, increase the chance of metastases and promote genome instability leading to additional malignant mutations.\nCharacterizing the mutations of malignant tissue has been instrumental for the development of the diagnosis, prognosis and treatment of cancer in the last decades. Cancer is a highly heterogeneous disease, and by knowing the type of mutations, we have a better understanding of the nature of tumors, and can apply precision medicine approaches, like targeted drug and immune therapy.\nCancer variants are somatic, which means that they exist in only a part of the cells in the tissue. Even in a sample of a solid tumor, only a part of the cells contains the driver mutations. This makes analysis of cancer variants more challenging than inherited variants, where we assume (almost) all cells have the same genome.\nIn this course, you will learn the concepts of calling somatic variants from next generation sequencing data, and the basics of performing cancer variant annotation. The practical work will be mainly based on the GATK4 (Mutect2) pipeline and Ensembl’s Variant Effect Predictor (VEP)."
  },
  {
    "objectID": "index.html#audience",
    "href": "index.html#audience",
    "title": "SIB course cancer variant analysis",
    "section": "Audience",
    "text": "Audience\nThis intermediate level course is addressed to researchers and clinicians who work with cancer biology and want to get started with performing somatic variant analysis and interpretation of the results."
  },
  {
    "objectID": "index.html#learning-outcomes",
    "href": "index.html#learning-outcomes",
    "title": "SIB course cancer variant analysis",
    "section": "Learning outcomes",
    "text": "Learning outcomes\nAt the end of the course, the participants should be able to:\n\nUnderstand the difference between germline and somatic variants and the implication of computational analysis\nPerform a somatic variant analysis on a paired sample (tumor – normal) with GATK4\nPerform a somatic variant annotation with VEP and use the results to filter possible high-impact mutations in the cancer genome"
  }
]